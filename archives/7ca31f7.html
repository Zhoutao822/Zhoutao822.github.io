<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://zhoutao822.coding.me').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="神经网络可太懒了 参考：  西瓜书第5章 神经网络  1. 神经元模型学过一点高中生物知识的我们都知道，对于有机生物来说，都是通过神经来控制躯体或者思维，电信号在神经上传导，并且要经过神经元的控制，只有被激活的神经元才能继续传递电信号。神经网络模型就类似于这种形式，在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将于神经元">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络">
<meta property="og:url" content="http://zhoutao822.coding.me/archives/7ca31f7.html">
<meta property="og:site_name" content="Tao">
<meta property="og:description" content="神经网络可太懒了 参考：  西瓜书第5章 神经网络  1. 神经元模型学过一点高中生物知识的我们都知道，对于有机生物来说，都是通过神经来控制躯体或者思维，电信号在神经上传导，并且要经过神经元的控制，只有被激活的神经元才能继续传递电信号。神经网络模型就类似于这种形式，在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将于神经元">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/mp.png">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/activate.png">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/perceptron.jpg">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/nn.jpg">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/bp.png">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/minima.png">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/som.png">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/cc.jpg">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/elman.gif">
<meta property="og:image" content="http://114.116.9.65:7777/images/2020/01/18/boltzmann.jpg">
<meta property="article:published_time" content="2018-11-07T09:37:59.000Z">
<meta property="article:modified_time" content="2020-01-18T14:44:16.706Z">
<meta property="article:author" content="Tao Zhou">
<meta property="article:tag" content="Theory">
<meta property="article:tag" content="Neural Network">
<meta property="article:tag" content="DNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://114.116.9.65:7777/images/2020/01/18/mp.png">

<link rel="canonical" href="http://zhoutao822.coding.me/archives/7ca31f7.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>神经网络 | Tao</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Tao" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zhoutao822.coding.me/archives/7ca31f7.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Tao Zhou">
      <meta itemprop="description" content="学习笔记">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tao">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          神经网络
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-11-07 17:37:59" itemprop="dateCreated datePublished" datetime="2018-11-07T17:37:59+08:00">2018-11-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-18 22:44:16" itemprop="dateModified" datetime="2020-01-18T22:44:16+08:00">2020-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>
            </span>

          
            <span id="/archives/7ca31f7.html" class="post-meta-item leancloud_visitors" data-flag-title="神经网络" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/7ca31f7.html#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/7ca31f7.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>神经网络可太懒了</strong></p>
<p>参考：</p>
<blockquote>
<p>西瓜书第5章 神经网络</p>
</blockquote>
<h2 id="1-神经元模型"><a href="#1-神经元模型" class="headerlink" title="1. 神经元模型"></a>1. 神经元模型</h2><p>学过一点高中生物知识的我们都知道，对于有机生物来说，都是通过神经来控制躯体或者思维，电信号在神经上传导，并且要经过神经元的控制，只有被激活的神经元才能继续传递电信号。神经网络模型就类似于这种形式，在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将于神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/mp.png" alt="mp.png"></p>
<p>理想视为激活函数应该是阶跃函数，只有“0/1”状态，但是阶跃函数不连续、不光滑，因此实际常用Sigmoid函数作为激活函数。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/activate.png" alt="activate.png"></p>
<p>把这些神经元按一定层次结构连接起来就得到神经网络。</p>
<a id="more"></a>

<h2 id="2-感知机与多层网络"><a href="#2-感知机与多层网络" class="headerlink" title="2. 感知机与多层网络"></a>2. 感知机与多层网络</h2><p>感知机由两层神经元组成，输入层接收外界信号传递给输出层，输出层是M-P神经元，感知机能容易地实现逻辑与、或、非。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/perceptron.jpg" alt="perceptron.jpg"></p>
<p>一般的，给定训练数据集，权重$w_i(i=1,2,…,n)$以及阈值$\theta$可以通过学习得到。若将$\theta$看作一个固定输入，对训练样本$(\boldsymbol{x}, y)$，若当前感知机的输出为$\hat{y}$，则感知机权重调整：</p>
<p>$$<br>wi \leftarrow w_i + \Delta w_i<br>\<br>\Delta w_i = \eta(y - \hat{y})x_i<br>$$</p>
<p>其中$\eta \in (0, 1)$称为学习率。若预测正确，则感知机不会变化，否则根据错误程度进行权重调整。感知机的求解形式非常类似线性模型中的分类，但是感知机无法实现非线性的问题求解，比如异或。</p>
<p>因此在输入层与输出层之间增加隐含层（至少为1），隐含层和输出层神经元都是拥有激活函数的功能神经元，这样就能对非线性问题进行拟合。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/nn.jpg" alt="nn.jpg"></p>
<h2 id="3-误差逆传播算法BP"><a href="#3-误差逆传播算法BP" class="headerlink" title="3. 误差逆传播算法BP"></a>3. 误差逆传播算法BP</h2><p>给定训练集$D = { (\boldsymbol{x}_1, \boldsymbol{y}_1) , (\boldsymbol{x}_2, \boldsymbol{y}_2),…,(\boldsymbol{x}_m, \boldsymbol{y}_m)}$，$\boldsymbol{x}_i \in \mathbb{R}^d ，\boldsymbol{y}_i \in \mathbb{R}^l$，即输入示例由$d$个属性描述，输出$l$维实值变量。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/bp.png" alt="bp.png"></p>
<p>如图神经网络结构：</p>
<ul>
<li>$d$个输入神经元，$l$个输出神经元，$q$个隐层神经元；</li>
<li>输出层第$j$个神经元的阈值用$\theta_j$表示，隐层第$h$个神经元的阈值用$\gamma_h$表示；</li>
<li>输入层第$i$个神经元与隐层第$h$个神经元之间的连接权为$v_{ih}$，隐层第$h$个神经元与输出层第$j$个神经元之间的连接权为$w_{hj}$；</li>
<li>隐层第$h$个神经元接收到的输入为$\alpha_h = \sum^d_{i=1}v_{ih}x_i$，输出层第$j$个神经元接收到的输入为$\beta_j = \sum^q_{h=1}w_{hj}b_h$，其中$b_h$为隐层第$h$个神经元的输出。假设激活函数均为Sigmoid。</li>
</ul>
<hr>
<p>对训练例$(\boldsymbol{x}_k, \boldsymbol{y}_k)$，假定神经网络的输出为$\hat{\boldsymbol{y}}_k = (\hat{y}^k_1,\hat{y}^k_2,…,\hat{y}^k_l)$，即</p>
<p>$$<br>\hat{y}^k_j = f(\beta_j-\theta_j)<br>$$<br>则网络在$(\boldsymbol{x}_k, \boldsymbol{y}_k)$上的均方误差MSE为</p>
<p>$$<br>E_k = \frac{1}{2}\sum^l_{j=1}(\hat{y}^k_j - y^k_j)^2，这里除以2是为了后面求导更简洁<br>$$</p>
<p>那么上图中的神经网络一共有$(d + l + 1)q + l$个参数需要确定：</p>
<ul>
<li>输入层到隐层的$d \times q$个权值；</li>
<li>隐层到输出层的$q \times l$个权值；</li>
<li>$q$个隐层神经元的阈值；</li>
<li>$l$个输出层神经元的阈值。</li>
</ul>
<p>同感知机的参数更新方式，对神经网络中的任意参数$v$：</p>
<p>$$<br>v \leftarrow v + \Delta v<br>$$</p>
<hr>
<p>以隐层到输出层的连接权$w_{hj}$为例进行推导。BP算法基于梯度下降策略，以目标的负梯度方向对参数进行调整。对误差$E_k$，给定学习率$\eta$，有</p>
<p>$$<br>\Delta w_{hj} = -\eta \frac{\partial E_k}{\partial w_{hj}}<br>$$</p>
<p>根据链式法则有</p>
<p>$$<br>\frac{\partial E_k}{\partial w_{hj}} = \frac{\partial E_k}{\partial \hat{y}^k_j} \cdot \frac{\partial \hat{y}^k_j}{\partial \beta_j} \cdot \frac{\partial \beta_j}{\partial w_{hj}}<br>$$</p>
<p>根据$\beta_j$的定义，显然有</p>
<p>$$<br>\frac{\partial \beta_j}{\partial w_{hj}} = b_h<br>$$</p>
<p>又因为Sigmoid函数有一个很好的性质：</p>
<p>$$<br>f’(x) = f(x) (1-f(x))<br>$$</p>
<p>于是令</p>
<p>$$<br>g_j = - \frac{\partial E_k}{\partial \hat{y}^k_j} \cdot \frac{\partial \hat{y}^k_j}{\partial \beta_j}<br>\<br>= -(\hat{y}^k_j - y^k_j)f’(\beta_j - \theta_j)<br>\<br>= \hat{y}^k_j(1- \hat{y}^k_j)(y^k_j - \hat{y}^k_j)<br>$$</p>
<p>代入上式，关于$w_{hj}$的更新公式</p>
<p>$$<br>\Delta w_{hj} = \eta g_j b_h<br>$$</p>
<p>类似可得</p>
<p>$$<br>\Delta \theta_j = - \eta g_j<br>\<br>\Delta v_{ih} = \eta e_h x_i<br>\<br>\Delta \gamma_h = - \eta e_h<br>$$</p>
<p>其中<br>$$<br>e_h = - \frac{\partial E_k}{\partial b_h} \cdot \frac{\partial b_h}{\partial \alpha_h}<br>\<br>= - \sum^l_{j=1}\frac{\partial E_k}{\partial \beta_j} \cdot \frac{\partial \beta_j}{\partial b_h} f’(\alpha_h - \gamma_h)<br>\<br>= \sum^l_{j=1}w_{hj}g_jf’(\alpha_h - \gamma_h)<br>\<br>= b_h(1 - b_h)\sum^l_{j=1}w_{hj}g_j<br>$$</p>
<p>学习率$\eta$控制算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛过慢，最终目的是使训练误差达到一个可以接受的较小的值。</p>
<p>对上面的推导来说，我们只考虑了一个样本，BP算法的目标是最小化训练集$D$上的累积误差</p>
<p>$$<br>E = \frac{1}{m}\sum^m_{k=1}E_k<br>$$</p>
<hr>
<p>将上述的参数组成矩阵或向量形式，可以简化运算公式，这里使用了某些其他符号代替图中的标记以及调整了阈值的符号</p>
<p>对每一个样本$(\boldsymbol{x}_k, \boldsymbol{y}_k)，\boldsymbol{x}_k \in \mathbb{R}^d ，\boldsymbol{y}_k \in \mathbb{R}^l$</p>
<p><strong>正向传播</strong></p>
<p>$$<br>\boldsymbol{Z}_0 = \boldsymbol{x}_k \boldsymbol{V} + \boldsymbol{\gamma} \quad \boldsymbol{V} \in \mathbb{R}^{d \times q}, \boldsymbol{\gamma} \in \mathbb{R}^{1 \times q}<br>\<br>\boldsymbol{A}_0 = f(\boldsymbol{Z}_0) \quad \boldsymbol{A}_0 \in \mathbb{R}^{1 \times q}<br>\<br>\boldsymbol{Z}_1 = \boldsymbol{A}_0 \boldsymbol{W} + \boldsymbol{\theta} \quad \boldsymbol{W} \in \mathbb{R}^{q \times l}, \boldsymbol{\theta} \in \mathbb{R}^{1 \times l}<br>\<br>\boldsymbol{A}_1 = f(\boldsymbol{Z}_1) \quad \boldsymbol{A}_1 \in \mathbb{R}^{1 \times l}<br>$$</p>
<p><strong>反向传播</strong></p>
<p>$$<br>\boldsymbol{g} = \boldsymbol{A}_1 \cdot (1- \boldsymbol{A}_1) \cdot (\boldsymbol{A}_1 - \boldsymbol{Y}) \quad \boldsymbol{Y},\boldsymbol{g} \in \mathbb{R}^{1 \times l}, 这里是点乘<br>\<br>d\boldsymbol{W} = \boldsymbol{A}_0^T\boldsymbol{g}<br>\<br>d\boldsymbol{\theta} = -\boldsymbol{g}<br>\<br>\boldsymbol{e} = \boldsymbol{A}_0 \cdot (\boldsymbol{A}_0 - 1) \cdot (\boldsymbol{g}\boldsymbol{W}^T) \quad \boldsymbol{e} \in \mathbb{R}^{1 \times q}<br>\<br>d\boldsymbol{V} = \boldsymbol{x}_k\boldsymbol{e}<br>\<br>d\boldsymbol{\gamma} = -\boldsymbol{e}<br>$$</p>
<p>参数$\boldsymbol{p}$更新方式为</p>
<p>$$<br>\boldsymbol{p} =  \boldsymbol{p} - d\boldsymbol{p}<br>$$</p>
<hr>
<ul>
<li>若每次参数更新都针对单个样例，则称为标准BP算法，缺点是参数更新频繁，需要计算量大（反向传播）；</li>
<li>若在读取整个训练集$D$一遍后才对参数进行更新，则称为累计BP算法，缺点是在一段时间后，梯度下降会非常缓慢，同样也会增大计算量（迭代次数增加）；</li>
<li>一般实际中采用的方式是将数据集$D$划分为多个batch，一个batch只包含固定数量的数据，这个batch的大小视具体情况而定，我们针对一个batch更新参数，这样就能避免仅使用标准BP算法和仅使用累计BP算法的缺点。</li>
</ul>
<blockquote>
<p>理论上已经证明，一个包含足够多神经元的隐层的多层前馈神经网络能以任意精度逼近任意复杂度的连续函数。然而，确定隐层神经元的个数是个未决问题，实际中使用“试错法”调整。</p>
</blockquote>
<p>既然BP神经网络有如此强大的拟合能力，那么必然会遇到过拟合的问题，解决方法是</p>
<ol>
<li>划分出验证集，根据训练集更新参数，验证集计算误差，当训练集误差下降而验证集误差上升时停止训练，并将参数返回；</li>
<li>正则化，令误差目标函数为</li>
</ol>
<p>$$<br>E = \lambda \frac{1}{m} \sum^m_{k=1}E_k + (1-\lambda)\sum_i w_i^2<br>$$</p>
<p>$\lambda \in (0,1)$，用于对经验误差与网络复杂度进行折中，常通过交叉验证法来估计。</p>
<h2 id="4-全局最小与局部最小"><a href="#4-全局最小与局部最小" class="headerlink" title="4. 全局最小与局部最小"></a>4. 全局最小与局部最小</h2><!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/minima.png" alt="minima.png"></p>
<p>由于神经网络考虑的参数数量非常大，那么很容易会遇到全局最小与局部极小的问题，我们可以将其想象成在一个坑坑洼洼的地面，我们需要找到最深的那个坑，最深的点即是最低的损失，即全局最小，构成这个坑的参数即是我们的神经网络的最优参数；</p>
<p>问题在于，梯度下降对初始值很敏感，如果我们在一个坑的边缘，那么梯度下降会沿着坑的最快下降梯度进行更新，即我们会沿着这个坑掉下去，若这个坑并不是最深的，那么我们就得不到最优解，最终陷入局部极小；</p>
<p>在现实任务中我们可以尝试跳出局部极小：</p>
<ul>
<li>多组不同的参数初始化神经网络，取最小误差的参数作为最终参数。相当于我们从不同的坑开始下降，看哪个坑最终的深度最大；</li>
<li>“模拟退火”技术，即在每一步都以一定概率接受比当前解更差的结果，并且在迭代过程中，接受“次优解”的概率要随着时间的推移逐渐降低，从而保证算法稳定。相当于我们在坑中不仅仅只是单纯的下降，我们需要以一定的概率往其他方向走，这个方向可以是深度不变的平移，也可以是深度增加的上升，类似于在坑中跳动，这样可以有几率跳出局部最小；</li>
<li>随机梯度下降，在计算梯度时加入了随机因素，即便陷入局部极小点，它计算出的梯度仍可能不为0，因此有机会跳出局部极小继续搜索。</li>
</ul>
<h2 id="5-其他常见神经网络"><a href="#5-其他常见神经网络" class="headerlink" title="5. 其他常见神经网络"></a>5. 其他常见神经网络</h2><h3 id="5-1-RBF网络"><a href="#5-1-RBF网络" class="headerlink" title="5.1 RBF网络"></a>5.1 RBF网络</h3><p>RBF（径向基函数）网络是一种单隐层前馈神经网络，使用径向基函数作为隐层神经元激活函数，而输出层是对隐层神经元输出的线性组合。假定输入为$d$维向量$\boldsymbol{x}$，输出为实值，则RBF网络可表示为</p>
<p>$$<br>\varphi(\boldsymbol{x}) = \sum^q_{i=1}w_i\rho(\boldsymbol{x},\boldsymbol{c}_i)<br>$$</p>
<p>其中$q$为隐层神经元个数，$\boldsymbol{c}_i$和$w_i$分别是第$i$个隐层神经元所对应的中心和权重，$\rho$是径向基函数，$\beta_i$与方差相关（一般也是参数），通常定义为样本$\boldsymbol{x}$到数据中心$\boldsymbol{c}_i$之间的欧式距离的单调函数。常用的高斯径向基函数形如</p>
<p>$$<br>\rho(\boldsymbol{x}, \boldsymbol{c}_i) = e^{-\beta_i||\boldsymbol{x} - \boldsymbol{c}_i||^2}<br>$$</p>
<blockquote>
<p>理论上已经证明，具有足够多隐层神经元的RBF网络能以任意精度逼近任意连续函数。</p>
</blockquote>
<p>通常采用两步来训练RBF网络：第一步，确定神经元中心$\boldsymbol{c}_i$，常用方式包括随机采样、聚类等；第二步，利用BP算法来确定参数$w_i$和$\beta_i$。</p>
<h3 id="5-2-ART网络"><a href="#5-2-ART网络" class="headerlink" title="5.2 ART网络"></a>5.2 ART网络</h3><p>ART（自适应谐振理论）网络是竞争学习的重要代表（竞争型学习是神经网络中一种常用的无监督策略，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制），该网络有比较层、识别层、识别阈值和重置模块构成。</p>
<ul>
<li>比较层负责接收输入样本，并将其传递给识别层神经元。识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类；</li>
<li>在接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元。竞争的最简单方式是，计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离，距离最小者获胜；</li>
<li>若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本被归为该代表向量所属类别，同时网络连接权将会更新，使得相似样本会计算出更大的相似度，从而增加获胜可能；</li>
<li>若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量设置为当前输入向量。</li>
</ul>
<h3 id="5-3-SOM网络"><a href="#5-3-SOM网络" class="headerlink" title="5.3 SOM网络"></a>5.3 SOM网络</h3><p>SOM（自组织映射）网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间（通常是二维），同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的点映射到网络输出层中的邻近神经元。</p>
<p>SOM网络中的输出层神经元以矩阵方式排列在二维空间中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置。SOM的训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。</p>
<p>SOM的训练过程：</p>
<ol>
<li>在接收到一个训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离，距离最近的神经元获胜，称为最佳匹配单元；</li>
<li>然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小；</li>
<li>重复上述过程，直到收敛。</li>
</ol>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/som.png" alt="som.png"></p>
<h3 id="5-4-级联相关网络"><a href="#5-4-级联相关网络" class="headerlink" title="5.4 级联相关网络"></a>5.4 级联相关网络</h3><p>级联相关网络是结构自适应网络的重要代表（一般的神经网络模型的结构是事先固定的，训练过程只是为了得到结构上的参数，而结构自适应网络则将网络结构也当作学习目标之一，并希望在训练过程中找到最符合数据特点的网络结构）。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/cc.jpg" alt="cc.jpg"></p>
<ul>
<li>级联是指建立层次连接的层级结构，在开始训练时，网络只有输入层和输出层，处于最小拓扑结构；随着训练的进行，新的隐层神经元逐渐加入，从而创建起层级结构，当新的隐层神经元加入时，其输入端连接权值是冻结固定的；</li>
<li>相关是指通过最大化新神经元的输出与网络误差之间的相关性来训练相关的参数。</li>
</ul>
<p>优缺点：无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。</p>
<h3 id="5-5-Elman网络"><a href="#5-5-Elman网络" class="headerlink" title="5.5 Elman网络"></a>5.5 Elman网络</h3><p>Elman网络是最常用的递归神经网络之一（递归神经网络允许网络中出现环形结构，使得网络在t时刻的输出状态不仅与$t$时刻的输入有关，还与$t-1$时刻的网络状态有关，从而能处理与时间有关的动态变化），其隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入，隐层神经元激活函数通常采用Sigmoid函数，训练使用BP算法。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/elman.gif" alt="elman.gif"></p>
<h3 id="5-6-Boltzmann机"><a href="#5-6-Boltzmann机" class="headerlink" title="5.6 Boltzmann机"></a>5.6 Boltzmann机</h3><p>Boltzmann机考虑神经网络具有某种状态，将这种状态定义为“能量”，通过训练使得能量函数最小化，最终网络达到理想状态。</p>
<!--  -->
<p><img src="http://114.116.9.65:7777/images/2020/01/18/boltzmann.jpg" alt="boltzmann.jpg"></p>
<p>常见的Boltzmann机神经元分类两层：显层和隐层。显层用于表示数据的输入与输出，隐层被理解为数据的内在表达。Boltzmann机中的神经元都是布尔型的（0/1），状态1表示激活，0表示抑制。令向量$\boldsymbol{s} \in { 0, 1 }^n$表示$n$个神经元的状态，$w_{ij}$表示神经元$i$与$j$之间的连接权，$\theta_i$表示神经元$i$的阈值，则状态向量$\boldsymbol{s}$所对应的Boltzmann机能量定义为</p>
<p>$$<br>E(\boldsymbol{s}) = -\sum^{n-1}<em>{i=1}\sum^n</em>{j=i+1}w_{ij}s_is_j - \sum^n_{i=1}\theta_is_i<br>$$</p>
<p>若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到Boltzmann分布，此时状态向量$\boldsymbol{s}$出现的概率将仅由其所有可能状态向量的能量确定：</p>
<p>$$<br>P(\boldsymbol{s}) = \frac{e^{-E(\boldsymbol{s})}}{\sum_{\boldsymbol{t}}e^{-E(\boldsymbol{t})}}<br>$$</p>
<p>Boltzmann机的训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大。标准的Boltzmann机是一个全连接图，难以解决现实任务。现实中常用受限Boltzmann机（RBM）。</p>
<p>受限Boltzmann机常用对比散度（CD）算法来进行训练。假定网络中有$d$个显层神经元和$q$个隐层神经元，令$\boldsymbol{v}$和$\boldsymbol{h}$分别表示显层与隐层的状态向量，由于同一层内不存在连接，有</p>
<p>$$<br>P(\boldsymbol{v}|\boldsymbol{h}) = \prod^d_{i=1}P(v_i|\boldsymbol{h})<br>\<br>P(\boldsymbol{h}|\boldsymbol{v}) = \prod^q_{j=1}P(h_j|\boldsymbol{v})<br>$$</p>
<p>CD算法对每个训练样本$\boldsymbol{v}$，先根据$P(\boldsymbol{h}|\boldsymbol{v})$计算出隐层神经元状态的概率分布，然后再根据这个概率分布采样得到$\boldsymbol{h}$，再根据$P(\boldsymbol{v}|\boldsymbol{h})$从$\boldsymbol{h}$产生$\boldsymbol{v}’$，再从$\boldsymbol{v}’$产生$\boldsymbol{h}’$；连接权的更新公式为</p>
<p>$$<br>\Delta w = \eta (\boldsymbol{v}\boldsymbol{h}^T - \boldsymbol{v}’\boldsymbol{h}’^T)<br>$$</p>
<h2 id="6-深度学习"><a href="#6-深度学习" class="headerlink" title="6. 深度学习"></a>6. 深度学习</h2><p>对于M-P神经元以及神经网络结构的思考：</p>
<ul>
<li>就单个神经元来说，它本质上还是在做线性回归的工作，通过激活函数，我们将线性回归的结果转换成了一种信息（不一定可以描述出来），同时激活函数一般来说会将输出限制在一个较小的范围（Sigmoid返回$(0,1)$），若将神经元连接起来，会避免出现输入值过大的情况；</li>
<li>每一层的神经元应该都是对来自上一层的输入的信息生成（集成？统计？），那么同一层的某些神经元可能会得到相同的结果，但是由于初始化参数不同，所以这种神经元等效的情况应该很少发生；</li>
<li>多层网络结构的目的是为了集成更详细的信息，输出层是将这些详细信息进行收集起来（线性回归），再使用输出层的激活函数，产生一个相对理想的预测值；</li>
<li>BP算法在神经网络中的作用，应该是希望对于每一层来说，都处于梯度下降过程，那么每一层的下降叠加起来可以使得神经网络有一个相对较快的整体的收敛速度。</li>
</ul>
<p>接下来会思考</p>
<ul>
<li>卷积神经网络CNN</li>
<li>循环神经网络RNN</li>
<li>长短期记忆LSTM</li>
<li>生成式对抗网络GAN</li>
<li>……</li>
</ul>

    </div>

    
    
    
      
  <div class="popular-posts-header">推荐文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/7d1dcda7.html" rel="bookmark">模型评估与选择</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/280b588e.html" rel="bookmark">支持向量机</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/8ddc7426.html" rel="bookmark">决策树</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/3e5788ab.html" rel="bookmark">深度学习-实际问题</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/c6767314.html" rel="bookmark">卷积神经网络</a></div>
    </li>
  </ul>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Tao Zhou
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://zhoutao822.coding.me/archives/7ca31f7.html" title="神经网络">http://zhoutao822.coding.me/archives/7ca31f7.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Theory/" rel="tag"># Theory</a>
              <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
              <a href="/tags/DNN/" rel="tag"># DNN</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/archives/8ddc7426.html" rel="prev" title="决策树">
      <i class="fa fa-chevron-left"></i> 决策树
    </a></div>
      <div class="post-nav-item">
    <a href="/archives/280b588e.html" rel="next" title="支持向量机">
      支持向量机 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-神经元模型"><span class="nav-text">1. 神经元模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-感知机与多层网络"><span class="nav-text">2. 感知机与多层网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-误差逆传播算法BP"><span class="nav-text">3. 误差逆传播算法BP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-全局最小与局部最小"><span class="nav-text">4. 全局最小与局部最小</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-其他常见神经网络"><span class="nav-text">5. 其他常见神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-RBF网络"><span class="nav-text">5.1 RBF网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-ART网络"><span class="nav-text">5.2 ART网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-SOM网络"><span class="nav-text">5.3 SOM网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-级联相关网络"><span class="nav-text">5.4 级联相关网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-Elman网络"><span class="nav-text">5.5 Elman网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-Boltzmann机"><span class="nav-text">5.6 Boltzmann机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-深度学习"><span class="nav-text">6. 深度学习</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tao Zhou"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Tao Zhou</p>
  <div class="site-description" itemprop="description">学习笔记</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tao Zhou</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">897k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">13:36</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    url = encodeURI(url);
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.getAttribute('id'));
      var title = visitors.getAttribute('data-flag-title');

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
              leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .catch(error => {
                console.error('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.getAttribute('id'));
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
            'X-LC-Key': 'xoukWFyqvFIXJ6DfxLLYtsTP',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
      appKey: 'xoukWFyqvFIXJ6DfxLLYtsTP',
      placeholder: "Just go go",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: false,
      lang: 'zh-cn' || 'zh-cn',
      path: location.pathname,
      recordIP: true,
      serverURLs: ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
