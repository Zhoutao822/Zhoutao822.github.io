<!-- build time:Sun Jan 19 2020 08:41:47 GMT+0800 (China Standard Time) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:new URL("http://zhoutao822.coding.me").hostname,root:"/",scheme:"Pisces",version:"7.7.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!0,preload:!0},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}}}</script><meta name="description" content="参考：  CIFAR-10 ResNetDeep Residual Learning for Image Recognition  源代码的参数完全按照论文Deep Residual Learning for Image Recognition描述指定。 CIFAR10项目下有6个py文件：cifar10.py, cifar10_main.py, cifar10_model.py, cifar10"><meta property="og:type" content="article"><meta property="og:title" content="TensorFlow-CIFAR10"><meta property="og:url" content="http://zhoutao822.coding.me/archives/40b4de0.html"><meta property="og:site_name" content="Tao"><meta property="og:description" content="参考：  CIFAR-10 ResNetDeep Residual Learning for Image Recognition  源代码的参数完全按照论文Deep Residual Learning for Image Recognition描述指定。 CIFAR10项目下有6个py文件：cifar10.py, cifar10_main.py, cifar10_model.py, cifar10"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2018-12-13T09:54:58.000Z"><meta property="article:modified_time" content="2020-01-17T15:07:46.285Z"><meta property="article:author" content="Tao Zhou"><meta property="article:tag" content="Code"><meta property="article:tag" content="Estimator"><meta property="article:tag" content="CNN"><meta property="article:tag" content="CIFAR-10"><meta name="twitter:card" content="summary"><link rel="canonical" href="http://zhoutao822.coding.me/archives/40b4de0.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0}</script><title>TensorFlow-CIFAR10 | Tao</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="Tao" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Tao</span> <span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://zhoutao822.coding.me/archives/40b4de0.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Tao Zhou"><meta itemprop="description" content="学习笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Tao"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">TensorFlow-CIFAR10</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-12-13 17:54:58" itemprop="dateCreated datePublished" datetime="2018-12-13T17:54:58+08:00">2018-12-13</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-01-17 23:07:46" itemprop="dateModified" datetime="2020-01-17T23:07:46+08:00">2020-01-17</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Coding/" itemprop="url" rel="index"><span itemprop="name">Coding</span> </a></span></span><span id="/archives/40b4de0.html" class="post-meta-item leancloud_visitors" data-flag-title="TensorFlow-CIFAR10" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/archives/40b4de0.html#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/archives/40b4de0.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>32k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>29 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>参考：</p><blockquote><p><a href="https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator" target="_blank" rel="noopener">CIFAR-10 ResNet</a><br><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p></blockquote><p>源代码的参数完全按照论文<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a>描述指定。</p><p>CIFAR10项目下有6个py文件：<code>cifar10.py, cifar10_main.py, cifar10_model.py, cifar10_utils.py, generate_cifar10_tfrecords.py, model_base.py</code></p><a id="more"></a><p>先从<code>generate_cifar10_tfrecords.py</code>开始</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""这部分代码的功能是生成TFRecords，这是专门提供给TensorFlow的一种数据格式。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">代码功能包括下载图片数据并解压，生成train，validation，eval三个.tfrecords文件作为训练集、验证集和测试集</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse <span class="comment"># 控制运行时参数，在__main__中使用</span></span><br><span class="line"><span class="keyword">import</span> os <span class="comment"># os.path.join 连接路径</span></span><br><span class="line"><span class="keyword">import</span> sys <span class="comment"># 获取系统相关信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tarfile <span class="comment"># 压缩/解压文件</span></span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle <span class="comment"># 序列化数据</span></span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange  <span class="comment"># python3中可以直接使用range，性能比python2中的range强</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">CIFAR_FILENAME = <span class="string">'cifar-10-python.tar.gz'</span></span><br><span class="line">CIFAR_DOWNLOAD_URL = <span class="string">'https://www.cs.toronto.edu/~kriz/'</span> + CIFAR_FILENAME <span class="comment"># 从这个url下载原始数据</span></span><br><span class="line">CIFAR_LOCAL_FOLDER = <span class="string">'cifar-10-batches-py'</span> <span class="comment"># 解压到本地的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_and_extract</span><span class="params">(data_dir)</span>:</span></span><br><span class="line">  <span class="comment"># download CIFAR-10 if not already downloaded.</span></span><br><span class="line">  <span class="comment"># maybe_download已经被1.12版本废弃，替代方法的是直接在keras中load_data，参考 卷积神经网络-coding</span></span><br><span class="line">  tf.contrib.learn.datasets.base.maybe_download(CIFAR_FILENAME, data_dir,</span><br><span class="line">                                                CIFAR_DOWNLOAD_URL)</span><br><span class="line">  tarfile.open(os.path.join(data_dir, CIFAR_FILENAME),</span><br><span class="line">               <span class="string">'r:gz'</span>).extractall(data_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据写入到TFRecords需要用到Feature，这是一种key-value的形式，同时我们可以定义value的类型，</span></span><br><span class="line"><span class="comment"># 一般有三种Int64List，BytesList，FloatList，顾名思义，value也必须是List形式</span></span><br><span class="line"><span class="comment"># 这里Int类型保存的是标签，Bytes类型保存图片数据，理论上来说，也可以用其他类型保存图片，</span></span><br><span class="line"><span class="comment"># 但是二进制字符串需要的空间比int或float小很多，而一张图片包含的数据量大，为了减小存储压力，</span></span><br><span class="line"><span class="comment"># 通常做法是将图片写为bytes类型，而label本身只是单值数字，所以可以用int。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_int64_feature</span><span class="params">(value)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_bytes_feature</span><span class="params">(value)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压后的文件包括data_batch_[1...5]和test_batch，这里将1到4作为训练集，5为验证集，</span></span><br><span class="line"><span class="comment"># 返回三种集合的文件名，这里的文件名没有后缀.XX</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_file_names</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Returns the file names expected to exist in the input_dir."""</span></span><br><span class="line">  file_names = &#123;&#125;</span><br><span class="line">  file_names[<span class="string">'train'</span>] = [<span class="string">'data_batch_%d'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="number">5</span>)]</span><br><span class="line">  file_names[<span class="string">'validation'</span>] = [<span class="string">'data_batch_5'</span>]</span><br><span class="line">  file_names[<span class="string">'eval'</span>] = [<span class="string">'test_batch'</span>]</span><br><span class="line">  <span class="keyword">return</span> file_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据文件路径将序列化的原始数据读取出来，使用tf.gfile.Open，rb代表二进制读，</span></span><br><span class="line"><span class="comment"># sys.version_info判断是python2还是python3，调用pickle.load转成python数据结构</span></span><br><span class="line"><span class="comment"># 根据convert_to_tfrecord里的代码可知，是一个字典类型的数据被序列化了</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_pickle_from_file</span><span class="params">(filename)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.gfile.Open(filename, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">if</span> sys.version_info &gt;= (<span class="number">3</span>, <span class="number">0</span>):</span><br><span class="line">      data_dict = pickle.load(f, encoding=<span class="string">'bytes'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      data_dict = pickle.load(f)</span><br><span class="line">  <span class="keyword">return</span> data_dict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入TFRecords的具体函数，两个参数都是文件的绝对路径</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_tfrecord</span><span class="params">(input_files, output_file)</span>:</span></span><br><span class="line">  <span class="string">"""Converts a file to TFRecords."""</span></span><br><span class="line">  print(<span class="string">'Generating %s'</span> % output_file)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># tf.python_io.TFRecordWriter在1.12中是tf.io.TFRecordWriter，对文件处理时采用的方式是</span></span><br><span class="line">  <span class="comment"># with XX as xx，这很常见，因为可以避免忘记关闭文件</span></span><br><span class="line">  <span class="keyword">with</span> tf.python_io.TFRecordWriter(output_file) <span class="keyword">as</span> record_writer:</span><br><span class="line">    <span class="keyword">for</span> input_file <span class="keyword">in</span> input_files:</span><br><span class="line">      <span class="comment"># 这里用b'xxxx'是因为原始数据使用了bytes字符串作为key而不是str，也是为了减少存储空间</span></span><br><span class="line">      <span class="comment"># len(labels)可以知道有多少条数据或图片</span></span><br><span class="line">      data_dict = read_pickle_from_file(input_file)</span><br><span class="line">      data = data_dict[<span class="string">b'data'</span>]</span><br><span class="line">      labels = data_dict[<span class="string">b'labels'</span>]</span><br><span class="line">      num_entries_in_batch = len(labels)</span><br><span class="line">      <span class="comment"># 注意了，record_writer.write是一条数据一条数据地往tfrecords中写入</span></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(num_entries_in_batch):</span><br><span class="line">        <span class="comment"># 写入地内容是tf.train.Example类型，对应上面地key-value形式</span></span><br><span class="line">        example = tf.train.Example(features=tf.train.Features(</span><br><span class="line">            feature=&#123;</span><br><span class="line">                <span class="string">'image'</span>: _bytes_feature(data[i].tobytes()), <span class="comment"># tobytes与tostring最终结果相同</span></span><br><span class="line">                <span class="string">'label'</span>: _int64_feature(labels[i])</span><br><span class="line">            &#125;))</span><br><span class="line">        <span class="comment"># SerializeToString序列化，必须步骤</span></span><br><span class="line">        record_writer.write(example.SerializeToString())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(data_dir)</span>:</span></span><br><span class="line">  print(<span class="string">'Download from &#123;&#125; and extract.'</span>.format(CIFAR_DOWNLOAD_URL))</span><br><span class="line">  <span class="comment"># 首先下载文件</span></span><br><span class="line">  download_and_extract(data_dir)</span><br><span class="line">  <span class="comment"># 获取文件名</span></span><br><span class="line">  file_names = _get_file_names()</span><br><span class="line">  <span class="comment"># 连接文件路径</span></span><br><span class="line">  input_dir = os.path.join(data_dir, CIFAR_LOCAL_FOLDER)</span><br><span class="line">  <span class="comment"># 分别对三种集合处理</span></span><br><span class="line">  <span class="keyword">for</span> mode, files <span class="keyword">in</span> file_names.items():</span><br><span class="line">    input_files = [os.path.join(input_dir, f) <span class="keyword">for</span> f <span class="keyword">in</span> files]</span><br><span class="line">    <span class="comment"># 保存的文件名为xxx.tfrecords</span></span><br><span class="line">    output_file = os.path.join(data_dir, mode + <span class="string">'.tfrecords'</span>)</span><br><span class="line">    <span class="comment"># 这里先删除已经存在的输出文件，不错</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      os.remove(output_file)</span><br><span class="line">    <span class="keyword">except</span> OSError:</span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># Convert to tf.train.Example and write the to TFRecords.</span></span><br><span class="line">    convert_to_tfrecord(input_files, output_file)</span><br><span class="line">  print(<span class="string">'Done!'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment"># 运行时参数控制，似乎可以使用tf.app.flags替代，只是指定了下载文件的路径</span></span><br><span class="line">  parser = argparse.ArgumentParser()</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--data-dir'</span>,</span><br><span class="line">      type=str,</span><br><span class="line">      default=<span class="string">''</span>,</span><br><span class="line">      help=<span class="string">'Directory to download and extract CIFAR-10 to.'</span>)</span><br><span class="line"></span><br><span class="line">  args = parser.parse_args()</span><br><span class="line">  main(args.data_dir)</span><br></pre></td></tr></table></figure><p>通过运行上面的py文件，我们得到了三个TFRecords文件，使用TFRecords文件的好处有，与直接使用原始数据相比，TensorFlow模型读取TFReocrds文件更快，内存压力更小，要知道，模型训练速度的瓶颈可能不是运算能力而是IO，配合tf.data.Dataset更快。还有就是生成的TFRecords文件可能比原始文件大。</p><hr><p>然后是<code>cifar10.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""这个代码的功能就很简单了，读取TFReocrds，生成Dataset"""</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片数据的原始形状，长宽为32，RGB图所以深度为3</span></span><br><span class="line">HEIGHT = <span class="number">32</span></span><br><span class="line">WIDTH = <span class="number">32</span></span><br><span class="line">DEPTH = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里定义一个类，超级方便后面的调用，封装了读取、处理数据一系列的方法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cifar10DataSet</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="string">"""Cifar10 data set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Described by http://www.cs.toronto.edu/~kriz/cifar.html.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># __init__是python类的初始化方法，参数包括：data_dir即三个TFRecords文件的路径</span></span><br><span class="line">  <span class="comment"># subset指定是train，validation还是eval，从而生成指定的Dataset，</span></span><br><span class="line">  <span class="comment"># 训练时train和validation，测试时eval，use_distortion指定是否需要扰乱数据集，</span></span><br><span class="line">  <span class="comment"># 图片扰乱一般包括裁剪、旋转、平移、翻转、亮度等等方式调整数据，从而增加模型的鲁棒性</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_dir, subset=<span class="string">'train'</span>, use_distortion=True)</span>:</span></span><br><span class="line">    self.data_dir = data_dir</span><br><span class="line">    self.subset = subset</span><br><span class="line">    self.use_distortion = use_distortion</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 获取文件路径名，返回了一个List类型</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_filenames</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.subset <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'validation'</span>, <span class="string">'eval'</span>]:</span><br><span class="line">      <span class="keyword">return</span> [os.path.join(self.data_dir, self.subset + <span class="string">'.tfrecords'</span>)]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Invalid data subset "%s"'</span> % self.subset)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将单个tf.Example还原为float32的图片数据和int32的label数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(self, serialized_example)</span>:</span></span><br><span class="line">    <span class="string">"""Parses a single tf.Example into image and label tensors."""</span></span><br><span class="line">    <span class="comment"># Dimensions of the images in the CIFAR-10 dataset.</span></span><br><span class="line">    <span class="comment"># See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the</span></span><br><span class="line">    <span class="comment"># input format.</span></span><br><span class="line">    <span class="comment"># 在1.12版本使用tf.io.parse_single_example，调用方式很简单，</span></span><br><span class="line">    <span class="comment"># FixedLenFeature代表固定长度的数据，图片对应是字节数组，所以按tf.string格式转换</span></span><br><span class="line">    features = tf.parse_single_example(</span><br><span class="line">        serialized_example,</span><br><span class="line">        features=&#123;</span><br><span class="line">            <span class="string">'image'</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">            <span class="string">'label'</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="comment"># 得到的数据需要解码，按照无符号8bit格式</span></span><br><span class="line">    image = tf.decode_raw(features[<span class="string">'image'</span>], tf.uint8)</span><br><span class="line">    image.set_shape([DEPTH * HEIGHT * WIDTH])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape from [depth * height * width] to [depth, height, width].</span></span><br><span class="line">    <span class="comment"># [depth, height, width]到[height, width, depth]，同时从uint8到float32</span></span><br><span class="line">    image = tf.cast(</span><br><span class="line">        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]),</span><br><span class="line">        tf.float32)</span><br><span class="line">    label = tf.cast(features[<span class="string">'label'</span>], tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用preprocess方法处理图片数据</span></span><br><span class="line">    image = self.preprocess(image)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 生成batch_size大小的Dataset</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">make_batch</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">    <span class="string">"""Read the images and labels from 'filenames'."""</span></span><br><span class="line">    filenames = self.get_filenames()</span><br><span class="line">    <span class="comment"># Repeat infinitely.</span></span><br><span class="line">    <span class="comment"># 注意这里使用了tf.data.TFRecordDataset读取TFRecords文件，repeat进行复制</span></span><br><span class="line">    dataset = tf.data.TFRecordDataset(filenames).repeat()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用map对每一个TFRecordDataset中读取的Example进行parser，</span></span><br><span class="line">    <span class="comment"># num_parallel_calls指定并行处理的数量，这里等于batch_size</span></span><br><span class="line">    dataset = dataset.map(</span><br><span class="line">        self.parser, num_parallel_calls=batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练集需要shuffle，buffer_size等于数据集40%的总数量加上3个batch_size</span></span><br><span class="line">    <span class="keyword">if</span> self.subset == <span class="string">'train'</span>:</span><br><span class="line">      min_queue_examples = int(</span><br><span class="line">          Cifar10DataSet.num_examples_per_epoch(self.subset) * <span class="number">0.4</span>)</span><br><span class="line">      <span class="comment"># Ensure that the capacity is sufficiently large to provide good random</span></span><br><span class="line">      <span class="comment"># shuffling.</span></span><br><span class="line">      dataset = dataset.shuffle(buffer_size=min_queue_examples + <span class="number">3</span> * batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Batch it up.</span></span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    iterator = dataset.make_one_shot_iterator()</span><br><span class="line">    image_batch, label_batch = iterator.get_next()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image_batch, label_batch</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 如果是train数据集，且扰动为真，resize_image_with_crop_or_pad填充图像到40长宽</span></span><br><span class="line">  <span class="comment"># 1.12版本tf.image.random_crop随机裁剪到32长宽</span></span><br><span class="line">  <span class="comment"># random_flip_left_right随机翻转图片</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">    <span class="string">"""Preprocess a single image in [height, width, depth] layout."""</span></span><br><span class="line">    <span class="keyword">if</span> self.subset == <span class="string">'train'</span> <span class="keyword">and</span> self.use_distortion:</span><br><span class="line">      <span class="comment"># Pad 4 pixels on each dimension of feature map, done in mini-batch</span></span><br><span class="line">      image = tf.image.resize_image_with_crop_or_pad(image, <span class="number">40</span>, <span class="number">40</span>)</span><br><span class="line">      image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])</span><br><span class="line">      image = tf.image.random_flip_left_right(image)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 静态方法，保存的是数据集大小，不需要实例</span></span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">num_examples_per_epoch</span><span class="params">(subset=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> subset == <span class="string">'train'</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="number">45000</span> <span class="comment"># 这里可能写错了？40000</span></span><br><span class="line">    <span class="keyword">elif</span> subset == <span class="string">'validation'</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="number">5000</span> <span class="comment"># 这里可能写错了？10000</span></span><br><span class="line">    <span class="keyword">elif</span> subset == <span class="string">'eval'</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="number">10000</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Invalid data subset "%s"'</span> % subset)</span><br></pre></td></tr></table></figure><p>上面的代码主要是为了训练模型提供Dataset，生成Dataset的过程中已经进行了数据扰动，而且这个类适用于三种不同的数据集。</p><hr><p>接着是<code>cifar10_utils.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">提供了运行时对模型的run_config，有很多部分是需要替换和丢弃的</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> six</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> tf_logging <span class="keyword">as</span> logging        <span class="comment"># 1.12版本 tf.logging.info</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.core.framework <span class="keyword">import</span> node_def_pb2                  <span class="comment"># 1.12版本 tf.NodeDef</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> device <span class="keyword">as</span> pydev             <span class="comment"># 1.12版本 tf.DeviceSpec</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.training <span class="keyword">import</span> basic_session_run_hooks      <span class="comment"># 1.12版本 tf.train.SecondOrStepTimer/tf.train.SessionRunArgs</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.training <span class="keyword">import</span> session_run_hook             <span class="comment"># 1.12版本 tf.train.SessionRunHook</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.training <span class="keyword">import</span> training_util                <span class="comment"># 1.12版本 tf.train.get_global_step</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.training <span class="keyword">import</span> device_setter                <span class="comment"># 1.12版本 tf.train.replica_device_setter</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.learn.python.learn <span class="keyword">import</span> run_config        <span class="comment"># 1.12版本 tf.estimator.RunConfig</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.12版本使用tf.estimator.RunConfig，废弃tf.contrib.learn.RunConfig，</span></span><br><span class="line"><span class="comment"># 而且在tf.estimator.RunConfig可以直接调用，不需要重写，此部分略过</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RunConfig</span><span class="params">(tf.contrib.learn.RunConfig)</span>:</span> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">uid</span><span class="params">(self, whitelist=None)</span>:</span></span><br><span class="line">    <span class="string">"""Generates a 'Unique Identifier' based on all internal fields.</span></span><br><span class="line"><span class="string">    Caller should use the uid string to check `RunConfig` instance integrity</span></span><br><span class="line"><span class="string">    in one session use, but should not rely on the implementation details, which</span></span><br><span class="line"><span class="string">    is subject to change.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      whitelist: A list of the string names of the properties uid should not</span></span><br><span class="line"><span class="string">        include. If `None`, defaults to `_DEFAULT_UID_WHITE_LIST`, which</span></span><br><span class="line"><span class="string">        includes most properties user allowes to change.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A uid string.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> whitelist <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      whitelist = run_config._DEFAULT_UID_WHITE_LIST</span><br><span class="line"></span><br><span class="line">    state = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> self.__dict__.items() <span class="keyword">if</span> <span class="keyword">not</span> k.startswith(<span class="string">'__'</span>)&#125;</span><br><span class="line">    <span class="comment"># Pop out the keys in whitelist.</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> whitelist:</span><br><span class="line">      state.pop(<span class="string">'_'</span> + k, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    ordered_state = collections.OrderedDict(</span><br><span class="line">        sorted(state.items(), key=<span class="keyword">lambda</span> t: t[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment"># For class instance without __repr__, some special cares are required.</span></span><br><span class="line">    <span class="comment"># Otherwise, the object address will be used.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'_cluster_spec'</span> <span class="keyword">in</span> ordered_state:</span><br><span class="line">      ordered_state[<span class="string">'_cluster_spec'</span>] = collections.OrderedDict(</span><br><span class="line">         sorted(ordered_state[<span class="string">'_cluster_spec'</span>].as_dict().items(),</span><br><span class="line">                key=<span class="keyword">lambda</span> t: t[<span class="number">0</span>])</span><br><span class="line">      )</span><br><span class="line">    <span class="keyword">return</span> <span class="string">', '</span>.join(</span><br><span class="line">        <span class="string">'%s=%r'</span> % (k, v) <span class="keyword">for</span> (k, v) <span class="keyword">in</span> six.iteritems(ordered_state)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># ExamplesPerSecondHook提供了在训练时输出xx examples/sec的功能，</span></span><br><span class="line"><span class="comment"># 本质上是tf.train.StepCounterHook乘以batch_size，所以可以使用StepCounterHook替换，</span></span><br><span class="line"><span class="comment"># 或者使用tf.train.LoggingTensorHook记录</span></span><br><span class="line"><span class="comment"># 使用tf.train.SessionRunHook替换继承的父类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExamplesPerSecondHook</span><span class="params">(session_run_hook.SessionRunHook)</span>:</span></span><br><span class="line">  <span class="string">"""Hook to print out examples per second.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Total time is tracked and then divided by the total number of steps</span></span><br><span class="line"><span class="string">    to get the average step time and then batch_size is used to determine</span></span><br><span class="line"><span class="string">    the running average of examples per second. The examples per second for the</span></span><br><span class="line"><span class="string">    most recent interval is also logged.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Hook的继承都差不多，主要包括几个方法，而且Hook一般用在Estimator中，与keras的callback有点不同</span></span><br><span class="line">  <span class="comment"># __init__，begin，before_run，after_run</span></span><br><span class="line">  <span class="comment"># 从__init__参数可以看出，estimator的log形式是按照steps或secs来输出的，默认为100steps打印一次</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      self,</span></span></span><br><span class="line"><span class="function"><span class="params">      batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">      every_n_steps=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">      every_n_secs=None,)</span>:</span></span><br><span class="line">    <span class="string">"""Initializer for ExamplesPerSecondHook.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      Args:</span></span><br><span class="line"><span class="string">      batch_size: Total batch size used to calculate examples/second from</span></span><br><span class="line"><span class="string">      global time.</span></span><br><span class="line"><span class="string">      every_n_steps: Log stats every n steps.</span></span><br><span class="line"><span class="string">      every_n_secs: Log stats every n seconds.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 这个判断形式确保二者至少有一个</span></span><br><span class="line">    <span class="keyword">if</span> (every_n_steps <span class="keyword">is</span> <span class="literal">None</span>) == (every_n_secs <span class="keyword">is</span> <span class="literal">None</span>):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'exactly one of every_n_steps'</span></span><br><span class="line">                       <span class="string">' and every_n_secs should be provided.'</span>)</span><br><span class="line">    <span class="comment"># 1.12版本使用tf.train.SecondOrStepTimer作为触发器，每n步或者n秒触发一次</span></span><br><span class="line">    self._timer = basic_session_run_hooks.SecondOrStepTimer(</span><br><span class="line">        every_steps=every_n_steps, every_secs=every_n_secs)</span><br><span class="line">    <span class="comment"># 初始化time和steps</span></span><br><span class="line">    self._step_train_time = <span class="number">0</span></span><br><span class="line">    self._total_steps = <span class="number">0</span></span><br><span class="line">    self._batch_size = batch_size</span><br><span class="line"></span><br><span class="line">  <span class="comment"># tf.train.get_global_step替换，用一个_global_step_tensor记录训练steps，训练开始时执行begin方法</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">begin</span><span class="params">(self)</span>:</span></span><br><span class="line">    self._global_step_tensor = training_util.get_global_step()</span><br><span class="line">    <span class="keyword">if</span> self._global_step_tensor <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      <span class="keyword">raise</span> RuntimeError(</span><br><span class="line">          <span class="string">'Global step should be created to use StepCounterHook.'</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># tf.train.SessionRunArgs替换，相当于把_global_step_tensor添加到Session.run()中</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">before_run</span><span class="params">(self, run_context)</span>:</span>  <span class="comment"># pylint: disable=unused-argument</span></span><br><span class="line">    <span class="keyword">return</span> basic_session_run_hooks.SessionRunArgs(self._global_step_tensor)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 在每一个step运行完成后通过触发器判断是否需要打印信息</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">after_run</span><span class="params">(self, run_context, run_values)</span>:</span></span><br><span class="line">    _ = run_context</span><br><span class="line">    <span class="comment"># 触发器与global_step对比</span></span><br><span class="line">    global_step = run_values.results</span><br><span class="line">    <span class="keyword">if</span> self._timer.should_trigger_for_step(global_step):</span><br><span class="line">      <span class="comment"># 获取两次触发器之间间隔的时间和steps</span></span><br><span class="line">      elapsed_time, elapsed_steps = self._timer.update_last_triggered_step(</span><br><span class="line">          global_step)</span><br><span class="line">      <span class="keyword">if</span> elapsed_time <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        steps_per_sec = elapsed_steps / elapsed_time</span><br><span class="line">        self._step_train_time += elapsed_time</span><br><span class="line">        self._total_steps += elapsed_steps</span><br><span class="line">        <span class="comment"># 用batch_size乘以steps/secs得到examples/secs得到平均值</span></span><br><span class="line">        average_examples_per_sec = self._batch_size * (</span><br><span class="line">            self._total_steps / self._step_train_time)</span><br><span class="line">        current_examples_per_sec = steps_per_sec * self._batch_size</span><br><span class="line">        <span class="comment"># Average examples/sec followed by current examples/sec</span></span><br><span class="line">        <span class="comment"># 1.12版本 tf.logging替换</span></span><br><span class="line">        logging.info(<span class="string">'%s: %g (%g), step = %g'</span>, <span class="string">'Average examples/sec'</span>,</span><br><span class="line">                     average_examples_per_sec, current_examples_per_sec,</span><br><span class="line">                     self._total_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.12版本使用tf.train.replica_device_setter替换，这个方法是为了配置在不同的device上运行</span></span><br><span class="line"><span class="comment"># 比如CPU和GPU或者多GPU，默认只用一个CPU device</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">local_device_setter</span><span class="params">(num_devices=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        ps_device_type=<span class="string">'cpu'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        worker_device=<span class="string">'/cpu:0'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        ps_ops=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                        ps_strategy=None)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> ps_ops == <span class="literal">None</span>:</span><br><span class="line">    ps_ops = [<span class="string">'Variable'</span>, <span class="string">'VariableV2'</span>, <span class="string">'VarHandleOp'</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ps_strategy <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># 必须替换的方法，返回下一个任务的索引？</span></span><br><span class="line">    <span class="comment"># Returns the next ps task index for placement in round-robin order</span></span><br><span class="line">    ps_strategy = device_setter._RoundRobinStrategy(num_devices)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> six.callable(ps_strategy):</span><br><span class="line">    <span class="keyword">raise</span> TypeError(<span class="string">"ps_strategy must be callable"</span>)</span><br><span class="line">  <span class="comment"># 获得device的规范名称，在with tf.device(DeviceSpec(job="train", ))中使用</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_local_device_chooser</span><span class="params">(op)</span>:</span></span><br><span class="line">    current_device = pydev.DeviceSpec.from_string(op.device <span class="keyword">or</span> <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">    node_def = op <span class="keyword">if</span> isinstance(op, node_def_pb2.NodeDef) <span class="keyword">else</span> op.node_def</span><br><span class="line">    <span class="keyword">if</span> node_def.op <span class="keyword">in</span> ps_ops:</span><br><span class="line">      ps_device_spec = pydev.DeviceSpec.from_string(</span><br><span class="line">          <span class="string">'/&#123;&#125;:&#123;&#125;'</span>.format(ps_device_type, ps_strategy(op)))</span><br><span class="line"></span><br><span class="line">      ps_device_spec.merge_from(current_device)</span><br><span class="line">      <span class="keyword">return</span> ps_device_spec.to_string()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      worker_device_spec = pydev.DeviceSpec.from_string(worker_device <span class="keyword">or</span> <span class="string">""</span>)</span><br><span class="line">      worker_device_spec.merge_from(current_device)</span><br><span class="line">      <span class="keyword">return</span> worker_device_spec.to_string()</span><br><span class="line">  <span class="keyword">return</span> _local_device_chooser</span><br></pre></td></tr></table></figure><p>这一部分的代码可以直接使用TensorFlow的函数替换，虽然重写也是可以的，了解了部分源码。</p><hr><p><code>model_base.py</code>里面是ResNet模型，这里不表，准备与其他模型例如VGG16，InceptionV3等等一起写一下。<br>这里看一下CIFAR10的模型<code>cifar10_model.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""Model class for Cifar10 Dataset."""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> model_base</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于ResNet的CIFAR10模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNetCifar10</span><span class="params">(model_base.ResNet)</span>:</span></span><br><span class="line">  <span class="string">"""Cifar10 model with ResNetV1 and basic residual block."""</span></span><br><span class="line">  <span class="comment"># num_layers模型层数，is_training模型处于train状态还是eval状态，</span></span><br><span class="line">  <span class="comment"># data_format表示图片数据中Depth处于第几个维度</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">               num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_training,</span></span></span><br><span class="line"><span class="function"><span class="params">               batch_norm_decay,</span></span></span><br><span class="line"><span class="function"><span class="params">               batch_norm_epsilon,</span></span></span><br><span class="line"><span class="function"><span class="params">               data_format=<span class="string">'channels_first'</span>)</span>:</span></span><br><span class="line">    super(ResNetCifar10, self).__init__(</span><br><span class="line">        is_training,</span><br><span class="line">        data_format,</span><br><span class="line">        batch_norm_decay,</span><br><span class="line">        batch_norm_epsilon</span><br><span class="line">    )</span><br><span class="line">    self.n = (num_layers - <span class="number">2</span>) // <span class="number">6</span></span><br><span class="line">    <span class="comment"># Add one in case label starts with 1. No impact if label starts with 0.</span></span><br><span class="line">    self.num_classes = <span class="number">10</span> + <span class="number">1</span></span><br><span class="line">    self.filters = [<span class="number">16</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>]</span><br><span class="line">    self.strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">  <span class="comment"># 前向传播，这里具体细节和ResNet相关，之后再分析，输出的x的维度是num_classes</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward_pass</span><span class="params">(self, x, input_data_format=<span class="string">'channels_last'</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Build the core model within the graph."""</span></span><br><span class="line">    <span class="keyword">if</span> self._data_format != input_data_format:</span><br><span class="line">      <span class="keyword">if</span> input_data_format == <span class="string">'channels_last'</span>:</span><br><span class="line">        <span class="comment"># Computation requires channels_first.</span></span><br><span class="line">        x = tf.transpose(x, [<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Computation requires channels_last.</span></span><br><span class="line">        x = tf.transpose(x, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Image standardization.</span></span><br><span class="line">    x = x / <span class="number">128</span> - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    x = self._conv(x, <span class="number">3</span>, <span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line">    x = self._batch_norm(x)</span><br><span class="line">    x = self._relu(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use basic (non-bottleneck) block and ResNet V1 (post-activation).</span></span><br><span class="line">    res_func = self._residual_v1</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3 stages of block stacking.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">      <span class="keyword">with</span> tf.name_scope(<span class="string">'stage'</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(self.n):</span><br><span class="line">          <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># First block in a stage, filters and strides may change.</span></span><br><span class="line">            x = res_func(x, <span class="number">3</span>, self.filters[i], self.filters[i + <span class="number">1</span>],</span><br><span class="line">                         self.strides[i])</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Following blocks in a stage, constant filters and unit stride.</span></span><br><span class="line">            x = res_func(x, <span class="number">3</span>, self.filters[i + <span class="number">1</span>], self.filters[i + <span class="number">1</span>], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = self._global_avg_pool(x)</span><br><span class="line">    x = self._fully_connected(x, self.num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><hr><p>最后是<code>cifar10_main.py</code>，包括train和eval部分功能，这里可能大部分代码需要重新写以适配新的版本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""ResNet model for classifying images from CIFAR-10 dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Support single-host training with one or multiple devices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ResNet as proposed in:</span></span><br><span class="line"><span class="string">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</span></span><br><span class="line"><span class="string">Deep Residual Learning for Image Recognition. arXiv:1512.03385</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">CIFAR-10 as in:</span></span><br><span class="line"><span class="string">http://www.cs.toronto.edu/~kriz/cifar.html</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> functools <span class="comment"># 作用于或返回其他函数的函数</span></span><br><span class="line"><span class="keyword">import</span> itertools <span class="comment"># chain() 可以把一组迭代对象串联起来，形成一个更大的迭代器</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">import</span> cifar10_model</span><br><span class="line"><span class="keyword">import</span> cifar10_utils</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> six</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange  <span class="comment"># pylint: disable=redefined-builtin</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置运行过程中所有函数能打印INFO级别的信息</span></span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义Estimator需要一个model_fn，返回值为一个tf.estimator.EstimatorSpec，</span></span><br><span class="line"><span class="comment"># 这里使用了私有方法_resnet_model_fn，是一种很常见的方式，因为TensorFlow中很多地方的参数是方法名，</span></span><br><span class="line"><span class="comment"># 通过私有方法可以简单的实现，或者用lambda形式也可以</span></span><br><span class="line"><span class="comment"># 三个参数num_gpus使用的GPU数量，variable_strategy使用CPU还是GPU，num_workers多进程处理数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_fn</span><span class="params">(num_gpus, variable_strategy, num_workers)</span>:</span></span><br><span class="line">  <span class="string">"""Returns a function that will build the resnet model."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_resnet_model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></span><br><span class="line">    <span class="string">"""Resnet model body.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Support single host, one or more GPU training. Parameter distribution can</span></span><br><span class="line"><span class="string">    be either one of the following scheme.</span></span><br><span class="line"><span class="string">    1. CPU is the parameter server and manages gradient updates.</span></span><br><span class="line"><span class="string">    2. Parameters are distributed evenly across all GPUs, and the first GPU</span></span><br><span class="line"><span class="string">       manages gradient updates.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      features: a list of tensors, one for each tower</span></span><br><span class="line"><span class="string">      labels: a list of tensors, one for each tower</span></span><br><span class="line"><span class="string">      mode: ModeKeys.TRAIN or EVAL</span></span><br><span class="line"><span class="string">      params: Hyperparameters suitable for tuning</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A EstimatorSpec object.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    is_training = (mode == tf.estimator.ModeKeys.TRAIN)</span><br><span class="line">    weight_decay = params.weight_decay <span class="comment"># 权重衰减</span></span><br><span class="line">    momentum = params.momentum <span class="comment"># 动量影响梯度下降速度，参考 深度学习-优化器</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tower表示处于不同device的数据，比如使用tower_losses记录分别在不同的device上产生的损失</span></span><br><span class="line">    <span class="comment"># 包括CPU和GPUs</span></span><br><span class="line">    tower_features = features</span><br><span class="line">    tower_labels = labels</span><br><span class="line">    tower_losses = [] <span class="comment"># 损失</span></span><br><span class="line">    tower_gradvars = [] <span class="comment"># 梯度</span></span><br><span class="line">    tower_preds = [] <span class="comment"># 预测值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># NHWC是TensorFlow的默认设置，并且NCHW是使用cuDNN在NVIDIA GPU上训练时使用的最佳格式。</span></span><br><span class="line">    <span class="comment"># 最佳实践是构建可同时处理两种数据格式的模型。这简化了对GPU的训练，然后在CPU上运行推理。</span></span><br><span class="line">    <span class="comment"># 如果使用英特尔MKL优化编译TensorFlow，则会优化和支持许多操作，尤其是与基于CNN的模型相关的操作NCHW。</span></span><br><span class="line">    <span class="comment"># 如果不使用MKL，则在使用时某些操作在CPU上不受支持NCHW。</span></span><br><span class="line">    <span class="comment"># 这两种格式的简要历史是TensorFlow开始使用，NHWC因为它在CPU上速度稍快。</span></span><br><span class="line">    data_format = params.data_format</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data_format:</span><br><span class="line">      <span class="keyword">if</span> num_gpus == <span class="number">0</span>:</span><br><span class="line">        data_format = <span class="string">'channels_last'</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        data_format = <span class="string">'channels_first'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_gpus == <span class="number">0</span>:</span><br><span class="line">      num_devices = <span class="number">1</span></span><br><span class="line">      device_type = <span class="string">'cpu'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      num_devices = num_gpus</span><br><span class="line">      device_type = <span class="string">'gpu'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># device的名称一般为'/cpu:0'或者'/gpu:1'</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_devices):</span><br><span class="line">      worker_device = <span class="string">'/&#123;&#125;:&#123;&#125;'</span>.format(device_type, i)</span><br><span class="line">      <span class="keyword">if</span> variable_strategy == <span class="string">'CPU'</span>:</span><br><span class="line">        <span class="comment"># 注意这里需要使用tf.train.replica_device_setter替换</span></span><br><span class="line">        device_setter = cifar10_utils.local_device_setter(</span><br><span class="line">            worker_device=worker_device)</span><br><span class="line">      <span class="comment"># GreedyLoadBalancingStrategy懒加载策略，tf.contrib.training下只有两个策略</span></span><br><span class="line">      <span class="comment"># 另一个是RandomStrategy</span></span><br><span class="line">      <span class="keyword">elif</span> variable_strategy == <span class="string">'GPU'</span>:</span><br><span class="line">        device_setter = cifar10_utils.local_device_setter(</span><br><span class="line">            ps_device_type=<span class="string">'gpu'</span>,</span><br><span class="line">            worker_device=worker_device,</span><br><span class="line">            ps_strategy=tf.contrib.training.GreedyLoadBalancingStrategy(</span><br><span class="line">                num_gpus, tf.contrib.training.byte_size_load_fn))</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">'resnet'</span>, reuse=bool(i != <span class="number">0</span>)):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'tower_%d'</span> % i) <span class="keyword">as</span> name_scope:</span><br><span class="line">          <span class="keyword">with</span> tf.device(device_setter):</span><br><span class="line">            <span class="comment"># 这里数据被预先分组了，比如均分给所有GPU，每个device只处理tower_features[i]和tower_labels[i]</span></span><br><span class="line">            <span class="comment"># 调用_tower_fn进行计算</span></span><br><span class="line">            loss, gradvars, preds = _tower_fn(</span><br><span class="line">                is_training, weight_decay, tower_features[i], tower_labels[i],</span><br><span class="line">                data_format, params.num_layers, params.batch_norm_decay,</span><br><span class="line">                params.batch_norm_epsilon)</span><br><span class="line">            <span class="comment"># 使用append把所有device的结果存入List中</span></span><br><span class="line">            tower_losses.append(loss)</span><br><span class="line">            tower_gradvars.append(gradvars)</span><br><span class="line">            tower_preds.append(preds)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">              <span class="comment"># Only trigger batch_norm moving mean and variance update from</span></span><br><span class="line">              <span class="comment"># the 1st tower. Ideally, we should grab the updates from all</span></span><br><span class="line">              <span class="comment"># towers but these stats accumulate extremely fast so we can</span></span><br><span class="line">              <span class="comment"># ignore the other stats from the other towers without</span></span><br><span class="line">              <span class="comment"># significant detriment.</span></span><br><span class="line">              <span class="comment"># batch_norm更新需要执行UPDATE_OPS操作，不会自动进行</span></span><br><span class="line">              update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS,</span><br><span class="line">                                             name_scope)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Now compute global loss and gradients.</span></span><br><span class="line">    gradvars = []</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'gradient_averaging'</span>):</span><br><span class="line">      all_grads = &#123;&#125;</span><br><span class="line">      <span class="keyword">for</span> grad, var <span class="keyword">in</span> itertools.chain(*tower_gradvars):</span><br><span class="line">        <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          all_grads.setdefault(var, []).append(grad)</span><br><span class="line">      <span class="keyword">for</span> var, grads <span class="keyword">in</span> six.iteritems(all_grads):</span><br><span class="line">        <span class="comment"># Average gradients on the same device as the variables</span></span><br><span class="line">        <span class="comment"># to which they apply.</span></span><br><span class="line">        <span class="keyword">with</span> tf.device(var.device):</span><br><span class="line">          <span class="keyword">if</span> len(grads) == <span class="number">1</span>:</span><br><span class="line">            avg_grad = grads[<span class="number">0</span>]</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 计算平均梯度，根据设备数来计算</span></span><br><span class="line">            avg_grad = tf.multiply(tf.add_n(grads), <span class="number">1.</span> / len(grads))</span><br><span class="line">        gradvars.append((avg_grad, var))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Device that runs the ops to apply global gradient updates.</span></span><br><span class="line">    consolidation_device = <span class="string">'/gpu:0'</span> <span class="keyword">if</span> variable_strategy == <span class="string">'GPU'</span> <span class="keyword">else</span> <span class="string">'/cpu:0'</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(consolidation_device):</span><br><span class="line">      <span class="comment"># 计算梯度完成后还需要执行梯度下降的运算，默认是cpu或者gpu1号</span></span><br><span class="line">      <span class="comment"># Suggested learning rate scheduling from</span></span><br><span class="line">      <span class="comment"># https://github.com/ppwwyyxx/tensorpack/blob/master/examples/ResNet/cifar10-resnet.py#L155</span></span><br><span class="line">      <span class="comment"># 使用多进程读取数据</span></span><br><span class="line">      num_batches_per_epoch = cifar10.Cifar10DataSet.num_examples_per_epoch(</span><br><span class="line">          <span class="string">'train'</span>) // (params.train_batch_size * num_workers)</span><br><span class="line">      boundaries = [</span><br><span class="line">          num_batches_per_epoch * x</span><br><span class="line">          <span class="keyword">for</span> x <span class="keyword">in</span> np.array([<span class="number">82</span>, <span class="number">123</span>, <span class="number">300</span>], dtype=np.int64)</span><br><span class="line">      ]</span><br><span class="line">      <span class="comment"># 学习率阶段性下降</span></span><br><span class="line">      staged_lr = [params.learning_rate * x <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">0.01</span>, <span class="number">0.002</span>]]</span><br><span class="line">      <span class="comment"># 在82steps后学习率减少到0.1倍，123后0.01倍，300后0.002倍</span></span><br><span class="line">      learning_rate = tf.train.piecewise_constant(tf.train.get_global_step(),</span><br><span class="line">                                                  boundaries, staged_lr)</span><br><span class="line">      <span class="comment"># 均值损失</span></span><br><span class="line">      loss = tf.reduce_mean(tower_losses, name=<span class="string">'loss'</span>)</span><br><span class="line">      <span class="comment"># ExamplesPerSecondHook打印训练速度</span></span><br><span class="line">      examples_sec_hook = cifar10_utils.ExamplesPerSecondHook(</span><br><span class="line">          params.train_batch_size, every_n_steps=<span class="number">10</span>)</span><br><span class="line">      <span class="comment"># 使用LoggingTensorHook打印learning_rate和loss</span></span><br><span class="line">      tensors_to_log = &#123;<span class="string">'learning_rate'</span>: learning_rate, <span class="string">'loss'</span>: loss&#125;</span><br><span class="line"></span><br><span class="line">      logging_hook = tf.train.LoggingTensorHook(</span><br><span class="line">          tensors=tensors_to_log, every_n_iter=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">      train_hooks = [logging_hook, examples_sec_hook]</span><br><span class="line">      <span class="comment"># 优化器使用MomentumOptimizer</span></span><br><span class="line">      optimizer = tf.train.MomentumOptimizer(</span><br><span class="line">          learning_rate=learning_rate, momentum=momentum)</span><br><span class="line">      <span class="comment"># 分布式优化器，暂时不了解</span></span><br><span class="line">      <span class="keyword">if</span> params.sync:</span><br><span class="line">        optimizer = tf.train.SyncReplicasOptimizer(</span><br><span class="line">            optimizer, replicas_to_aggregate=num_workers)</span><br><span class="line">        sync_replicas_hook = optimizer.make_session_run_hook(params.is_chief)</span><br><span class="line">        train_hooks.append(sync_replicas_hook)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Create single grouped train op</span></span><br><span class="line">      train_op = [</span><br><span class="line">          optimizer.apply_gradients(</span><br><span class="line">              gradvars, global_step=tf.train.get_global_step())</span><br><span class="line">      ]</span><br><span class="line">      train_op.extend(update_ops)</span><br><span class="line">      train_op = tf.group(*train_op)</span><br><span class="line">      <span class="comment"># concat横向连接</span></span><br><span class="line">      predictions = &#123;</span><br><span class="line">          <span class="string">'classes'</span>:</span><br><span class="line">              tf.concat([p[<span class="string">'classes'</span>] <span class="keyword">for</span> p <span class="keyword">in</span> tower_preds], axis=<span class="number">0</span>),</span><br><span class="line">          <span class="string">'probabilities'</span>:</span><br><span class="line">              tf.concat([p[<span class="string">'probabilities'</span>] <span class="keyword">for</span> p <span class="keyword">in</span> tower_preds], axis=<span class="number">0</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      stacked_labels = tf.concat(labels, axis=<span class="number">0</span>)</span><br><span class="line">      metrics = &#123;</span><br><span class="line">          <span class="string">'accuracy'</span>:</span><br><span class="line">              tf.metrics.accuracy(stacked_labels, predictions[<span class="string">'classes'</span>])</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment"># 返回EstimatorSpec</span></span><br><span class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">        mode=mode,</span><br><span class="line">        predictions=predictions,</span><br><span class="line">        loss=loss,</span><br><span class="line">        train_op=train_op,</span><br><span class="line">        training_hooks=train_hooks,</span><br><span class="line">        eval_metric_ops=metrics)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> _resnet_model_fn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算loss, gradvars, preds的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_tower_fn</span><span class="params">(is_training, weight_decay, feature, label, data_format,</span></span></span><br><span class="line"><span class="function"><span class="params">              num_layers, batch_norm_decay, batch_norm_epsilon)</span>:</span></span><br><span class="line">  <span class="string">"""Build computation tower (Resnet).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    is_training: true if is training graph.</span></span><br><span class="line"><span class="string">    weight_decay: weight regularization strength, a float.</span></span><br><span class="line"><span class="string">    feature: a Tensor.</span></span><br><span class="line"><span class="string">    label: a Tensor.</span></span><br><span class="line"><span class="string">    data_format: channels_last (NHWC) or channels_first (NCHW).</span></span><br><span class="line"><span class="string">    num_layers: number of layers, an int.</span></span><br><span class="line"><span class="string">    batch_norm_decay: decay for batch normalization, a float.</span></span><br><span class="line"><span class="string">    batch_norm_epsilon: epsilon for batch normalization, a float.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    A tuple with the loss for the tower, the gradients and parameters, and</span></span><br><span class="line"><span class="string">    predictions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># 构建模型</span></span><br><span class="line">  model = cifar10_model.ResNetCifar10(</span><br><span class="line">      num_layers,</span><br><span class="line">      batch_norm_decay=batch_norm_decay,</span><br><span class="line">      batch_norm_epsilon=batch_norm_epsilon,</span><br><span class="line">      is_training=is_training,</span><br><span class="line">      data_format=data_format)</span><br><span class="line">  <span class="comment"># 前向传播计算结果logits</span></span><br><span class="line">  logits = model.forward_pass(feature, input_data_format=<span class="string">'channels_last'</span>)</span><br><span class="line">  tower_pred = &#123;</span><br><span class="line">      <span class="string">'classes'</span>: tf.argmax(input=logits, axis=<span class="number">1</span>),</span><br><span class="line">      <span class="string">'probabilities'</span>: tf.nn.softmax(logits)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  tower_loss = tf.losses.sparse_softmax_cross_entropy(</span><br><span class="line">      logits=logits, labels=label)</span><br><span class="line">  tower_loss = tf.reduce_mean(tower_loss)</span><br><span class="line"></span><br><span class="line">  model_params = tf.trainable_variables()</span><br><span class="line">  <span class="comment"># 对loss增加l2范数约束，衰减权重为weight_decay</span></span><br><span class="line">  tower_loss += weight_decay * tf.add_n(</span><br><span class="line">      [tf.nn.l2_loss(v) <span class="keyword">for</span> v <span class="keyword">in</span> model_params])</span><br><span class="line"></span><br><span class="line">  tower_grad = tf.gradients(tower_loss, model_params)</span><br><span class="line">  <span class="comment"># 返回值包括model_params模型参数</span></span><br><span class="line">  <span class="keyword">return</span> tower_loss, zip(tower_grad, model_params), tower_pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_dir,</span></span></span><br><span class="line"><span class="function"><span class="params">             subset,</span></span></span><br><span class="line"><span class="function"><span class="params">             num_shards,</span></span></span><br><span class="line"><span class="function"><span class="params">             batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">             use_distortion_for_training=True)</span>:</span></span><br><span class="line">  <span class="string">"""Create input graph for model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    data_dir: Directory where TFRecords representing the dataset are located.</span></span><br><span class="line"><span class="string">    subset: one of 'train', 'validate' and 'eval'.</span></span><br><span class="line"><span class="string">    num_shards: num of towers participating in data-parallel training.</span></span><br><span class="line"><span class="string">    batch_size: total batch size for training to be divided by the number of</span></span><br><span class="line"><span class="string">    shards.</span></span><br><span class="line"><span class="string">    use_distortion_for_training: True to use distortions.</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    two lists of tensors for features and labels, each of num_shards length.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    use_distortion = subset == <span class="string">'train'</span> <span class="keyword">and</span> use_distortion_for_training</span><br><span class="line">    dataset = cifar10.Cifar10DataSet(data_dir, subset, use_distortion)</span><br><span class="line">    image_batch, label_batch = dataset.make_batch(batch_size)</span><br><span class="line">    <span class="keyword">if</span> num_shards &lt;= <span class="number">1</span>:</span><br><span class="line">      <span class="comment"># No GPU available or only 1 GPU.</span></span><br><span class="line">      <span class="keyword">return</span> [image_batch], [label_batch]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note that passing num=batch_size is safe here, even though</span></span><br><span class="line">    <span class="comment"># dataset.batch(batch_size) can, in some cases, return fewer than batch_size</span></span><br><span class="line">    <span class="comment"># examples. This is because it does so only when repeating for a limited</span></span><br><span class="line">    <span class="comment"># number of epochs, but our dataset repeats forever.</span></span><br><span class="line">    <span class="comment"># 把image_batch分解为batch_size个张量，axis为0，刚好是batch_size的维度[i, x, x, x]，</span></span><br><span class="line">    <span class="comment"># 然后将这batch_size个张量根据循环报数规则分配给num_shards个进程</span></span><br><span class="line">    image_batch = tf.unstack(image_batch, num=batch_size, axis=<span class="number">0</span>)</span><br><span class="line">    label_batch = tf.unstack(label_batch, num=batch_size, axis=<span class="number">0</span>)</span><br><span class="line">    feature_shards = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(num_shards)]</span><br><span class="line">    label_shards = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(num_shards)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(batch_size):</span><br><span class="line">      idx = i % num_shards</span><br><span class="line">      feature_shards[idx].append(image_batch[i])</span><br><span class="line">      label_shards[idx].append(label_batch[i])</span><br><span class="line">    feature_shards = [tf.parallel_stack(x) <span class="keyword">for</span> x <span class="keyword">in</span> feature_shards]</span><br><span class="line">    label_shards = [tf.parallel_stack(x) <span class="keyword">for</span> x <span class="keyword">in</span> label_shards]</span><br><span class="line">    <span class="keyword">return</span> feature_shards, label_shards</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.contrib.learn.Experiment全部丢弃，需要用根据tf.estimator重新构建Estimator，</span></span><br><span class="line"><span class="comment"># 使用train_spec和eval_spec，调用tf.estimator.train_and_evaluate</span></span><br><span class="line"><span class="comment"># 同样这里使用了私有方法</span></span><br><span class="line"><span class="comment"># 重写</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_experiment_fn</span><span class="params">(data_dir,</span></span></span><br><span class="line"><span class="function"><span class="params">                      num_gpus,</span></span></span><br><span class="line"><span class="function"><span class="params">                      variable_strategy,</span></span></span><br><span class="line"><span class="function"><span class="params">                      use_distortion_for_training=True)</span>:</span></span><br><span class="line">  <span class="string">"""Returns an Experiment function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Experiments perform training on several workers in parallel,</span></span><br><span class="line"><span class="string">  in other words experiments know how to invoke train and eval in a sensible</span></span><br><span class="line"><span class="string">  fashion for distributed training. Arguments passed directly to this</span></span><br><span class="line"><span class="string">  function are not tunable, all other arguments should be passed within</span></span><br><span class="line"><span class="string">  tf.HParams, passed to the enclosed function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      data_dir: str. Location of the data for input_fns.</span></span><br><span class="line"><span class="string">      num_gpus: int. Number of GPUs on each worker.</span></span><br><span class="line"><span class="string">      variable_strategy: String. CPU to use CPU as the parameter server</span></span><br><span class="line"><span class="string">      and GPU to use the GPUs as the parameter server.</span></span><br><span class="line"><span class="string">      use_distortion_for_training: bool. See cifar10.Cifar10DataSet.</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">      A function (tf.estimator.RunConfig, tf.contrib.training.HParams) -&gt;</span></span><br><span class="line"><span class="string">      tf.contrib.learn.Experiment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      Suitable for use by tf.contrib.learn.learn_runner, which will run various</span></span><br><span class="line"><span class="string">      methods on Experiment (train, evaluate) based on information</span></span><br><span class="line"><span class="string">      about the current runner in `run_config`.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_experiment_fn</span><span class="params">(run_config, hparams)</span>:</span></span><br><span class="line">    <span class="string">"""Returns an Experiment."""</span></span><br><span class="line">    <span class="comment"># Create estimator.</span></span><br><span class="line">    train_input_fn = functools.partial(</span><br><span class="line">        input_fn,</span><br><span class="line">        data_dir,</span><br><span class="line">        subset=<span class="string">'train'</span>,</span><br><span class="line">        num_shards=num_gpus,</span><br><span class="line">        batch_size=hparams.train_batch_size,</span><br><span class="line">        use_distortion_for_training=use_distortion_for_training)</span><br><span class="line"></span><br><span class="line">    eval_input_fn = functools.partial(</span><br><span class="line">        input_fn,</span><br><span class="line">        data_dir,</span><br><span class="line">        subset=<span class="string">'eval'</span>,</span><br><span class="line">        batch_size=hparams.eval_batch_size,</span><br><span class="line">        num_shards=num_gpus)</span><br><span class="line"></span><br><span class="line">    num_eval_examples = cifar10.Cifar10DataSet.num_examples_per_epoch(<span class="string">'eval'</span>)</span><br><span class="line">    <span class="keyword">if</span> num_eval_examples % hparams.eval_batch_size != <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(</span><br><span class="line">          <span class="string">'validation set size must be multiple of eval_batch_size'</span>)</span><br><span class="line"></span><br><span class="line">    train_steps = hparams.train_steps</span><br><span class="line">    eval_steps = num_eval_examples // hparams.eval_batch_size</span><br><span class="line"> </span><br><span class="line">    classifier = tf.estimator.Estimator(</span><br><span class="line">        model_fn=get_model_fn(num_gpus, variable_strategy,</span><br><span class="line">                              run_config.num_worker_replicas <span class="keyword">or</span> <span class="number">1</span>),</span><br><span class="line">        config=run_config,</span><br><span class="line">        params=hparams)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create experiment.</span></span><br><span class="line">    <span class="keyword">return</span> tf.contrib.learn.Experiment(</span><br><span class="line">        classifier,</span><br><span class="line">        train_input_fn=train_input_fn,</span><br><span class="line">        eval_input_fn=eval_input_fn,</span><br><span class="line">        train_steps=train_steps,</span><br><span class="line">        eval_steps=eval_steps)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> _experiment_fn</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.contrib.learn.learn_runner.run要丢弃了，这里重写</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(job_dir, data_dir, num_gpus, variable_strategy,</span></span></span><br><span class="line"><span class="function"><span class="params">         use_distortion_for_training, log_device_placement, num_intra_threads,</span></span></span><br><span class="line"><span class="function"><span class="params">         **hparams)</span>:</span></span><br><span class="line">  <span class="comment"># The env variable is on deprecation path, default is set to off.</span></span><br><span class="line">  os.environ[<span class="string">'TF_SYNC_ON_FINISH'</span>] = <span class="string">'0'</span></span><br><span class="line">  os.environ[<span class="string">'TF_ENABLE_WINOGRAD_NONFUSED'</span>] = <span class="string">'1'</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Session configuration.</span></span><br><span class="line">  sess_config = tf.ConfigProto(</span><br><span class="line">      allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">      log_device_placement=log_device_placement,</span><br><span class="line">      intra_op_parallelism_threads=num_intra_threads,</span><br><span class="line">      gpu_options=tf.GPUOptions(force_gpu_compatible=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">  config = cifar10_utils.RunConfig(</span><br><span class="line">      session_config=sess_config, model_dir=job_dir)</span><br><span class="line">  tf.contrib.learn.learn_runner.run(</span><br><span class="line">      get_experiment_fn(data_dir, num_gpus, variable_strategy,</span><br><span class="line">                        use_distortion_for_training),</span><br><span class="line">      run_config=config,</span><br><span class="line">      hparams=tf.contrib.training.HParams(</span><br><span class="line">          is_chief=config.is_chief,</span><br><span class="line">          **hparams))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面全是配置运行时参数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  parser = argparse.ArgumentParser()</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--data-dir'</span>,</span><br><span class="line">      type=str,</span><br><span class="line">      required=<span class="literal">True</span>,</span><br><span class="line">      help=<span class="string">'The directory where the CIFAR-10 input data is stored.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--job-dir'</span>,</span><br><span class="line">      type=str,</span><br><span class="line">      required=<span class="literal">True</span>,</span><br><span class="line">      help=<span class="string">'The directory where the model will be stored.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--variable-strategy'</span>,</span><br><span class="line">      choices=[<span class="string">'CPU'</span>, <span class="string">'GPU'</span>],</span><br><span class="line">      type=str,</span><br><span class="line">      default=<span class="string">'CPU'</span>,</span><br><span class="line">      help=<span class="string">'Where to locate variable operations'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--num-gpus'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">1</span>,</span><br><span class="line">      help=<span class="string">'The number of gpus used. Uses only CPU if set to 0.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--num-layers'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">44</span>,</span><br><span class="line">      help=<span class="string">'The number of layers of the model.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--train-steps'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">80000</span>,</span><br><span class="line">      help=<span class="string">'The number of steps to use for training.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--train-batch-size'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">128</span>,</span><br><span class="line">      help=<span class="string">'Batch size for training.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--eval-batch-size'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">100</span>,</span><br><span class="line">      help=<span class="string">'Batch size for validation.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--momentum'</span>,</span><br><span class="line">      type=float,</span><br><span class="line">      default=<span class="number">0.9</span>,</span><br><span class="line">      help=<span class="string">'Momentum for MomentumOptimizer.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--weight-decay'</span>,</span><br><span class="line">      type=float,</span><br><span class="line">      default=<span class="number">2e-4</span>,</span><br><span class="line">      help=<span class="string">'Weight decay for convolutions.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--learning-rate'</span>,</span><br><span class="line">      type=float,</span><br><span class="line">      default=<span class="number">0.1</span>,</span><br><span class="line">      help=<span class="string">"""\</span></span><br><span class="line"><span class="string">      This is the inital learning rate value. The learning rate will decrease</span></span><br><span class="line"><span class="string">      during training. For more details check the model_fn implementation in</span></span><br><span class="line"><span class="string">      this file.\</span></span><br><span class="line"><span class="string">      """</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--use-distortion-for-training'</span>,</span><br><span class="line">      type=bool,</span><br><span class="line">      default=<span class="literal">True</span>,</span><br><span class="line">      help=<span class="string">'If doing image distortion for training.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--sync'</span>,</span><br><span class="line">      action=<span class="string">'store_true'</span>,</span><br><span class="line">      default=<span class="literal">False</span>,</span><br><span class="line">      help=<span class="string">"""\</span></span><br><span class="line"><span class="string">      If present when running in a distributed environment will run on sync mode.\</span></span><br><span class="line"><span class="string">      """</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--num-intra-threads'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">0</span>,</span><br><span class="line">      help=<span class="string">"""\</span></span><br><span class="line"><span class="string">      Number of threads to use for intra-op parallelism. When training on CPU</span></span><br><span class="line"><span class="string">      set to 0 to have the system pick the appropriate number or alternatively</span></span><br><span class="line"><span class="string">      set it to the number of physical CPU cores.\</span></span><br><span class="line"><span class="string">      """</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--num-inter-threads'</span>,</span><br><span class="line">      type=int,</span><br><span class="line">      default=<span class="number">0</span>,</span><br><span class="line">      help=<span class="string">"""\</span></span><br><span class="line"><span class="string">      Number of threads to use for inter-op parallelism. If set to 0, the</span></span><br><span class="line"><span class="string">      system will pick an appropriate number.\</span></span><br><span class="line"><span class="string">      """</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--data-format'</span>,</span><br><span class="line">      type=str,</span><br><span class="line">      default=<span class="literal">None</span>,</span><br><span class="line">      help=<span class="string">"""\</span></span><br><span class="line"><span class="string">      If not set, the data format best for the training device is used. </span></span><br><span class="line"><span class="string">      Allowed values: channels_first (NCHW) channels_last (NHWC).\</span></span><br><span class="line"><span class="string">      """</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--log-device-placement'</span>,</span><br><span class="line">      action=<span class="string">'store_true'</span>,</span><br><span class="line">      default=<span class="literal">False</span>,</span><br><span class="line">      help=<span class="string">'Whether to log device placement.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--batch-norm-decay'</span>,</span><br><span class="line">      type=float,</span><br><span class="line">      default=<span class="number">0.997</span>,</span><br><span class="line">      help=<span class="string">'Decay for batch norm.'</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">'--batch-norm-epsilon'</span>,</span><br><span class="line">      type=float,</span><br><span class="line">      default=<span class="number">1e-5</span>,</span><br><span class="line">      help=<span class="string">'Epsilon for batch norm.'</span>)</span><br><span class="line">  args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> args.num_gpus &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">assert</span> tf.test.is_gpu_available(), <span class="string">"Requested GPUs but none found."</span></span><br><span class="line">  <span class="keyword">if</span> args.num_gpus &lt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(</span><br><span class="line">        <span class="string">'Invalid GPU count: \"--num-gpus\" must be 0 or a positive integer.'</span>)</span><br><span class="line">  <span class="keyword">if</span> args.num_gpus == <span class="number">0</span> <span class="keyword">and</span> args.variable_strategy == <span class="string">'GPU'</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'num-gpus=0, CPU must be used as parameter server. Set'</span></span><br><span class="line">                     <span class="string">'--variable-strategy=CPU.'</span>)</span><br><span class="line">  <span class="keyword">if</span> (args.num_layers - <span class="number">2</span>) % <span class="number">6</span> != <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'Invalid --num-layers parameter.'</span>)</span><br><span class="line">  <span class="keyword">if</span> args.num_gpus != <span class="number">0</span> <span class="keyword">and</span> args.train_batch_size % args.num_gpus != <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'--train-batch-size must be multiple of --num-gpus.'</span>)</span><br><span class="line">  <span class="keyword">if</span> args.num_gpus != <span class="number">0</span> <span class="keyword">and</span> args.eval_batch_size % args.num_gpus != <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'--eval-batch-size must be multiple of --num-gpus.'</span>)</span><br><span class="line"></span><br><span class="line">  main(**vars(args))</span><br></pre></td></tr></table></figure></div><div class="popular-posts-header">推荐文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/467d5b64.html" rel="bookmark">卷积神经网络-coding</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/c516f6f0.html" rel="bookmark">线性模型-coding</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/2d6320ff.html" rel="bookmark">神经网络-coding</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/120687ac.html" rel="bookmark">决策树-coding</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/archives/28da5216.html" rel="bookmark">循环神经网络-coding</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>Tao Zhou</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://zhoutao822.coding.me/archives/40b4de0.html" title="TensorFlow-CIFAR10">http://zhoutao822.coding.me/archives/40b4de0.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Code/" rel="tag"># Code</a> <a href="/tags/Estimator/" rel="tag"># Estimator</a> <a href="/tags/CNN/" rel="tag"># CNN</a> <a href="/tags/CIFAR-10/" rel="tag"># CIFAR-10</a></div><div class="post-nav"><div class="post-nav-item"><a href="/archives/cbc488cf.html" rel="prev" title="语音识别-DNN-HMM混合系统"><i class="fa fa-chevron-left"></i> 语音识别-DNN-HMM混合系统</a></div><div class="post-nav-item"><a href="/archives/4981e084.html" rel="next" title="深度学习模型-KerasApplications">深度学习模型-KerasApplications <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="valine-comments"></div><script>window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Tao Zhou" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">Tao Zhou</p><div class="site-description" itemprop="description">学习笔记</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">61</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">6</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">126</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="cc-license motion-element" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">Tao Zhou</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">897k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">13:36</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.0</div><script>function leancloudSelector(url) {
    url = encodeURI(url);
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.getAttribute('id'));
      var title = visitors.getAttribute('data-flag-title');

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
              leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .catch(error => {
                console.error('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.getAttribute('id'));
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
            'X-LC-Key': 'xoukWFyqvFIXJ6DfxLLYtsTP',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });</script></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });</script><script>NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);</script><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
      appKey: 'xoukWFyqvFIXJ6DfxLLYtsTP',
      placeholder: "Just go go",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: false,
      lang: 'zh-cn' || 'zh-cn',
      path: location.pathname,
      recordIP: true,
      serverURLs: ''
    });
  }, window.Valine);
});</script></body></html><!-- rebuild by neat -->