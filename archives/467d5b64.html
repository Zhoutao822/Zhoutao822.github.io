<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://zhoutao822.coding.me').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="1. 数据集说明  1.1 多分类图像数据集-MNIST  数据来源：tf.keras.datasets.mnist.load_data； 数据集形状：训练集60000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个28×2828 \times 2828×28的数组，即灰度图像，大小范围0255，标签是图片对应的数字09，数据集中每个数字出现不是均等">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络-coding">
<meta property="og:url" content="http://zhoutao822.coding.me/archives/467d5b64.html">
<meta property="og:site_name" content="Tao">
<meta property="og:description" content="1. 数据集说明  1.1 多分类图像数据集-MNIST  数据来源：tf.keras.datasets.mnist.load_data； 数据集形状：训练集60000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个28×2828 \times 2828×28的数组，即灰度图像，大小范围0255，标签是图片对应的数字09，数据集中每个数字出现不是均等">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-12-04T03:54:50.000Z">
<meta property="article:modified_time" content="2020-01-17T15:07:46.281Z">
<meta property="article:author" content="Tao Zhou">
<meta property="article:tag" content="Code">
<meta property="article:tag" content="Estimator">
<meta property="article:tag" content="Keras">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="MNIST">
<meta property="article:tag" content="CIFAR-10">
<meta property="article:tag" content="Kaggle dog &amp; cat">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://zhoutao822.coding.me/archives/467d5b64.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>卷积神经网络-coding | Tao</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Tao" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Tao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zhoutao822.coding.me/archives/467d5b64.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Tao Zhou">
      <meta itemprop="description" content="学习笔记">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tao">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          卷积神经网络-coding
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-04 11:54:50" itemprop="dateCreated datePublished" datetime="2018-12-04T11:54:50+08:00">2018-12-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-17 23:07:46" itemprop="dateModified" datetime="2020-01-17T23:07:46+08:00">2020-01-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Coding/" itemprop="url" rel="index">
                    <span itemprop="name">Coding</span>
                  </a>
                </span>
            </span>

          
            <span id="/archives/467d5b64.html" class="post-meta-item leancloud_visitors" data-flag-title="卷积神经网络-coding" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/467d5b64.html#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/467d5b64.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>42k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>38 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="1-数据集说明"><a class="markdownIt-Anchor" href="#1-数据集说明"></a> 1. 数据集说明</h2>
<h3 id="11-多分类图像数据集-mnist"><a class="markdownIt-Anchor" href="#11-多分类图像数据集-mnist"></a> 1.1 多分类图像数据集-MNIST</h3>
<ul>
<li>数据来源：<code>tf.keras.datasets.mnist.load_data</code>；</li>
<li>数据集形状：训练集60000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>28</mn><mo>×</mo><mn>28</mn></mrow><annotation encoding="application/x-tex">28 \times 28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">8</span></span></span></span>的数组，即灰度图像，大小范围0<sub>255，标签是图片对应的数字0</sub>9，数据集中每个数字出现不是均等的，训练集<code>0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949</code>，测试集<code>0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009</code>；</li>
<li>数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；</li>
<li>性能度量：accuracy。</li>
</ul>
<h3 id="12-二分类图像数据集-kaggle-dog-cat"><a class="markdownIt-Anchor" href="#12-二分类图像数据集-kaggle-dog-cat"></a> 1.2 二分类图像数据集-kaggle dog &amp; cat</h3>
<ul>
<li>数据来源：<a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data" target="_blank" rel="noopener"><code>Dogsvs.CatsRedux:KernelsEdition|Kaggle</code></a>；</li>
<li>数据集形状：训练集25000个样本，测试集12500个样本，每个样本都是一张彩色图片，大小不定，训练集中图片名称即包含标签信息，测试集无标签，最后需要提交预测的结果到kaggle进行评分，预测结果为图片标签为<code>dog</code>的概率；</li>
<li>数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；</li>
<li>性能度量：交叉熵或accuracy。</li>
</ul>
<h3 id="13-多分类数据集-cifar-10"><a class="markdownIt-Anchor" href="#13-多分类数据集-cifar-10"></a> 1.3 多分类数据集-CIFAR-10</h3>
<ul>
<li>数据来源：<code>tf.keras.datasets.cifar10.load_data</code>；</li>
<li>数据集形状：训练集50000个样本，测试集10000个样本，每个样本包括两个部分：图片数据和标签，每个样本的图片数据是一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>32</mn><mo>×</mo><mn>32</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">32 \times 32 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>的数组，即彩色图像，大小范围0<sub>255，标签是图片对应的种类0</sub>9，分别对应<code>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck</code>，数据集中每个种类出现是均等的；</li>
<li>数据集划分：在训练集中随机选出20%数据作为验证集，剩下80%用于训练，验证集用于调整超参数以及网络架构；</li>
<li>性能度量：accuracy。</li>
</ul>
<a id="more"></a>
<h2 id="2-tensorflow卷积神经网络应用"><a class="markdownIt-Anchor" href="#2-tensorflow卷积神经网络应用"></a> 2. Tensorflow卷积神经网络应用</h2>
<p>参考：</p>
<blockquote>
<p><a href="https://github.com/aymericdamien/TensorFlow-Examples/" target="_blank" rel="noopener"><code>Github-TensorFlow-Examples</code></a><br />
<a href="https://www.tensorflow.org/tutorials/" target="_blank" rel="noopener"><code>Tensorflow Tutorials</code></a></p>
</blockquote>
<h3 id="21-eager模式实现手写数字分类"><a class="markdownIt-Anchor" href="#21-eager模式实现手写数字分类"></a> 2.1 Eager模式实现手写数字分类</h3>
<p><strong>数据集使用的是Tensorflow下的MNIST</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Eager模式必须手动开启，2.0版本将会是默认，Eager模型可以边运行边观察结果</span></span><br><span class="line">tf.enable_eager_execution()</span><br><span class="line">tfe = tf.contrib.eager</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Tensorflow version: '</span>, tf.VERSION, <span class="string">'\n'</span>, <span class="string">'Eager mode: '</span>, tf.executing_eagerly())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置超参数</span></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">num_steps = <span class="number">20000</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">display_step = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'train size:'</span>, x_train.shape, y_train.shape)</span><br><span class="line">print(<span class="string">'test size:'</span>, x_test.shape, y_test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里需要reshape图片，原始图片是28*28，这里转换成28*28*1，标签需要转换成onehot变量便于后面计算交叉熵，axis=-1，可以使标签转换成m*depth的形状</span></span><br><span class="line">x_train = tf.reshape(tf.cast(x_train, tf.float32), shape=[<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">x_test = tf.reshape(tf.cast(x_test, tf.float32), shape=[<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">y_train = tf.one_hot(y_train, depth=<span class="number">10</span>, axis=<span class="number">-1</span>)</span><br><span class="line">y_test = tf.one_hot(y_test, depth=<span class="number">10</span>, axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造输入的dataset，注意Eager模式需要使用tfe调用迭代器Iterator</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(<span class="number">1000</span>).batch(batch_size)</span><br><span class="line">dataset_iter = tfe.Iterator(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个CNN类，Eager模式需要继承自tfe.Network，推荐废弃，使用keras取代</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(tfe.Network)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.conv2d_1 = self.track_layer(</span><br><span class="line">            tf.layers.Conv2D(<span class="number">32</span>, <span class="number">5</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.conv2d_2 = self.track_layer(</span><br><span class="line">            tf.layers.Conv2D(<span class="number">64</span>, <span class="number">5</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.maxpool = self.track_layer(</span><br><span class="line">            tf.layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>))</span><br><span class="line">        self.flatten = self.track_layer(</span><br><span class="line">            tf.layers.Flatten()) </span><br><span class="line">        self.fclayer = self.track_layer(</span><br><span class="line">            tf.layers.Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.dropout = self.track_layer(</span><br><span class="line">            tf.layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">        self.out_layer = self.track_layer(</span><br><span class="line">            tf.layers.Dense(num_classes))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x, training=True)</span>:</span></span><br><span class="line">        x = self.conv2d_1(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line">        x = self.conv2d_2(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.fclayer(x)</span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            x = self.dropout(x)</span><br><span class="line">        <span class="keyword">return</span> self.out_layer(x)</span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数，softmax_cross_entropy_with_logits_v2包含两步，首先计算softmax，再计算交叉熵，需要注意</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn</span><span class="params">(inference_fn, inputs, labels)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">        logits = inference_fn(inputs), labels = labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义计算准确率的函数，这里通过argmax取softmax中最高的那个概率的索引，也就是对应的数字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy_fn</span><span class="params">(inference_fn, inputs, labels, training)</span>:</span></span><br><span class="line">    prediction = tf.nn.softmax(inference_fn(inputs, training))</span><br><span class="line">    correct_pred = tf.equal(tf.argmax(prediction, <span class="number">1</span>), tf.argmax(labels, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Eager模式的梯度计算方式implicit_gradients</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">grad = tfe.implicit_gradients(loss_fn)</span><br><span class="line"></span><br><span class="line">average_loss = <span class="number">0.</span></span><br><span class="line">average_acc = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(num_steps):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        d = dataset_iter.next()</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        dataset_iter = tfe.Iterator(dataset)</span><br><span class="line">        d = dataset_iter.next()</span><br><span class="line"></span><br><span class="line">    x_batch = d[<span class="number">0</span>]</span><br><span class="line">    y_batch = tf.cast(d[<span class="number">1</span>], tf.int64)</span><br><span class="line"></span><br><span class="line">    batch_loss = loss_fn(cnn, x_batch, y_batch)</span><br><span class="line">    average_loss += batch_loss</span><br><span class="line"></span><br><span class="line">    batch_accuracy = accuracy_fn(cnn, x_batch, y_batch, <span class="literal">False</span>)</span><br><span class="line">    average_acc += batch_accuracy</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Initial loss= &#123;:.6f&#125;"</span>.format(average_loss))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Eager模式参数梯度下降</span></span><br><span class="line">    optimizer.apply_gradients(grad(cnn, x_batch, y_batch))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (step + <span class="number">1</span>) % display_step == <span class="number">0</span> <span class="keyword">or</span> step == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> step &gt; <span class="number">0</span>:</span><br><span class="line">            average_loss /= display_step</span><br><span class="line">            average_acc /= display_step</span><br><span class="line">        print(<span class="string">"Step:"</span>, <span class="string">'%04d'</span> % (step + <span class="number">1</span>), <span class="string">" loss="</span>,</span><br><span class="line">              <span class="string">"&#123;:.6f&#125;"</span>.format(average_loss), <span class="string">" accuracy="</span>,</span><br><span class="line">              <span class="string">"&#123;:.4f&#125;"</span>.format(average_acc))</span><br><span class="line">        average_loss = <span class="number">0.</span></span><br><span class="line">        average_acc = <span class="number">0.</span></span><br><span class="line">        </span><br><span class="line">test_acc = accuracy_fn(cnn, x_test, y_test, <span class="literal">False</span>)</span><br><span class="line">print(<span class="string">'Testset accuracy: &#123;:.4f&#125;'</span>.format(test_acc))</span><br></pre></td></tr></table></figure>
<p>训练时间有点长</p>
<p><code>Testset accuracy: 0.9916</code></p>
<h3 id="22-keras实现手写数字分类"><a class="markdownIt-Anchor" href="#22-keras实现手写数字分类"></a> 2.2 Keras实现手写数字分类</h3>
<p>使用Keras一方面可以简化代码，比如神经网络模型构建过程简化，Dropout层自动判断属于train阶段还是evaluate阶段，另一方面输出结果自动显示，不需要手动print。所以，推荐使用keras或者其他自定义estimator完成机器学习任务。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Tensorflow version: '</span>, tf.VERSION)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">steps_per_epoch = <span class="number">1000</span> <span class="comment"># 一般等于 样本总数/batch_size</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">epochs = <span class="number">20</span> <span class="comment"># 训练轮数，即循环使用整个数据集的次数</span></span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里缩放了图像的灰度值，为了加速收敛，为了满足model的输入形状，reshape为(28,28,1)，这里不需要将标签转换为onehot类型</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()</span><br><span class="line">x_train , x_test = x_train / <span class="number">255.</span> , x_test / <span class="number">255.</span></span><br><span class="line">x_train = tf.reshape(x_train, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">x_test = tf.reshape(x_test, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">print(<span class="string">'train size:'</span>, x_train.shape, y_train.shape)</span><br><span class="line">print(<span class="string">'test size:'</span>, x_test.shape, y_test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建dataset，增加了repeat，是为了可以循环使用数据集</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(<span class="number">1000</span>).batch(batch_size).repeat()</span><br><span class="line"></span><br><span class="line"><span class="comment"># keras构建模型的方式就很简单了，直接选择需要的layer堆叠起来</span></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    <span class="comment"># Conv2D卷积层，需要定义filters，kernel_size，strides，padding，activation，首层还需要input_shape，必须是(height, width, channel)</span></span><br><span class="line">    layers.Conv2D(<span class="number">32</span>, <span class="number">5</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">    <span class="comment"># MaxPool2D池化层，需要定义pool_size，strides，padding</span></span><br><span class="line">    layers.MaxPool2D(<span class="number">2</span>, padding=<span class="string">'SAME'</span>),</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, <span class="number">5</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.MaxPool2D(<span class="number">2</span>, padding=<span class="string">'SAME'</span>),</span><br><span class="line"></span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    <span class="comment"># Dropout丢弃层，这里的0.5是丢弃率，有些函数里是保留率，需要注意</span></span><br><span class="line">    layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    layers.Dense(num_classes, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置优化器optimizer，损失函数loss，这里使用sparse_categorical_crossentropy是因为label为数字，categorical_crossentropy对应label为onehot，以及evaluate时使用的准则metrics</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># summary会展示模型的结构，包括每一层参数个数，每一层输入形状</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)</span><br><span class="line"></span><br><span class="line">model.evaluate(x_test, y_test, steps=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>使用CPU训练大概一个半小时</p>
<blockquote>
<p>loss: 0.0226<br />
accuracy: 0.9925</p>
</blockquote>
<h3 id="23-基于keras使用预训练的网络实现猫狗识别"><a class="markdownIt-Anchor" href="#23-基于keras使用预训练的网络实现猫狗识别"></a> 2.3 基于Keras使用预训练的网络实现猫狗识别</h3>
<p>首先导入需要的库，这里我们可以直接使用keras自带的已经训练好的网络，比如VGG16</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Sequential </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os <span class="comment"># 用于文件路径</span></span><br><span class="line"><span class="keyword">import</span> shutil <span class="comment"># 用于文件复制</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Tensorflow version: '</span>, tf.VERSION)</span><br></pre></td></tr></table></figure>
<p>然后设置一些可能会用到的超参数，这里训练集25000张图片等于<code>batch_size * steps_per_epoch</code>，以及图片长宽</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line">steps_per_epoch = <span class="number">1250</span></span><br><span class="line">img_height = <span class="number">150</span></span><br><span class="line">img_width = <span class="number">150</span></span><br><span class="line">img_channels = <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>为了测试代码，我们先不使用整个数据集，而是从原始数据集中划分出一小部分数据进行测试（需要修改上面的超参数），在确定代码无误后，我们需要修改这部分代码，因为训练集是完整的train文件夹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们从原始的train文件夹下，分别选择猫和狗的前2000张作为训练集，之后的500作为验证集</span></span><br><span class="line">base_dir = <span class="string">'C:/Users/Admin/Downloads/dogvscat'</span></span><br><span class="line">original_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择的图片存放在small文件夹下</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'small_train'</span>)</span><br><span class="line">eval_dir = os.path.join(base_dir, <span class="string">'small_eval'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_dir):</span><br><span class="line">    os.mkdir(train_dir)</span><br><span class="line">    os.mkdir(eval_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2500</span>):</span><br><span class="line">    name = <span class="string">'cat.&#123;&#125;.jpg'</span>.format(i)</span><br><span class="line">    src = os.path.join(original_dir, name)</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="number">2000</span>:</span><br><span class="line">        dst = os.path.join(train_dir, name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dst = os.path.join(eval_dir, name)</span><br><span class="line">    shutil.copyfile(src, dst) <span class="comment"># 复制图片</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2500</span>):</span><br><span class="line">    name = <span class="string">'dog.&#123;&#125;.jpg'</span>.format(i)</span><br><span class="line">    src = os.path.join(original_dir, name)</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="number">2000</span>:</span><br><span class="line">        dst = os.path.join(train_dir, name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dst = os.path.join(eval_dir, name)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>
<p>准备输入数据，包括两部分，一个是图片绝对路径，一个是标签（dog为1，cat为0）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个shuffle函数，使用np.random.permutation生成随机序列，保证路径与标签一一对应</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unison_shuffled_copies</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    a = np.array(a)</span><br><span class="line">    b = np.array(b)</span><br><span class="line">    <span class="keyword">assert</span> len(a) == len(b)</span><br><span class="line">    p = np.random.permutation(len(a))</span><br><span class="line">    <span class="keyword">return</span> a[p], b[p]</span><br><span class="line"></span><br><span class="line">files = os.listdir(train_dir)</span><br><span class="line">train_files = [os.path.join(train_dir, name) <span class="keyword">for</span> name <span class="keyword">in</span> files]</span><br><span class="line">train_labels = np.array([<span class="string">'dog'</span> <span class="keyword">in</span> name <span class="keyword">for</span> name <span class="keyword">in</span> files]).astype(np.float)</span><br><span class="line">train_files, train_labels = unison_shuffled_copies(train_files, train_labels)</span><br><span class="line"></span><br><span class="line">files = os.listdir(eval_dir)</span><br><span class="line">eval_files = [os.path.join(eval_dir, name) <span class="keyword">for</span> name <span class="keyword">in</span> files]</span><br><span class="line">eval_labels = np.array([<span class="string">'dog'</span> <span class="keyword">in</span> name <span class="keyword">for</span> name <span class="keyword">in</span> files]).astype(np.float)</span><br><span class="line">eval_files, eval_labels = unison_shuffled_copies(eval_files, eval_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个地方应该是bug，Tensorflow version 1.12.0，keras的model使用predict需要target和label，而label对于需要预测的数据来说无意义，随便设置为-1</span></span><br><span class="line">files = [<span class="string">'&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">12501</span>)]</span><br><span class="line">test_files = [os.path.join(test_dir, name) <span class="keyword">for</span> name <span class="keyword">in</span> files]</span><br><span class="line">test_labels = np.array([<span class="number">-1</span>] * len(files)).astype(np.float) <span class="comment"># 理论上不需要这个</span></span><br></pre></td></tr></table></figure>
<p>我们需要把图片绝对路径转换为图片数据，在输入函数中解决</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_input_fn</span><span class="params">(filenames, labels=None, shuffle=False, repeat_count=<span class="number">1</span>, batch_size=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 读取数据，解码，resize图片，归一化（这里只是除以255）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_read_img</span><span class="params">(filename, label=None)</span>:</span></span><br><span class="line">        img_raw = tf.read_file(filename)</span><br><span class="line">        img = tf.image.decode_image(img_raw, channels=<span class="number">3</span>)</span><br><span class="line">        img.set_shape([<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]) <span class="comment"># decode_image需要，decode_jpeg不需要</span></span><br><span class="line">        img = tf.image.resize_images(img, [img_height, img_width])</span><br><span class="line">        img = tf.divide(img, <span class="number">255.</span>)</span><br><span class="line">        img.set_shape([img_height, img_width, img_channels])</span><br><span class="line">        <span class="comment"># 理论上测试数据集的label为空，但是keras不允许，对应上面的bug</span></span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> img</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> img, label</span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        dataset = tf.data.Dataset.from_tensor_slices(filenames)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))</span><br><span class="line">    dataset = dataset.map(_read_img)</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(<span class="number">2000</span>)</span><br><span class="line">    dataset = dataset.batch(batch_size).repeat(repeat_count)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>
<p>定义训练模型，我这里定义了两个注释掉的部分是使用预训练VGG16，VGG16的参数不变，仅训练连接层的参数，这样需要的内存比较小；没有注释的部分是自定义的model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vgg16 = VGG16(</span></span><br><span class="line"><span class="comment">#     weights='imagenet',</span></span><br><span class="line"><span class="comment">#     include_top=False,</span></span><br><span class="line"><span class="comment">#     input_shape=(img_height, img_width, img_channels))</span></span><br><span class="line"><span class="comment"># model = Sequential([</span></span><br><span class="line"><span class="comment">#     vgg16,</span></span><br><span class="line"><span class="comment">#     layers.Flatten(),</span></span><br><span class="line"><span class="comment">#     layers.Dropout(0.5),</span></span><br><span class="line"><span class="comment">#     layers.Dense(1, activation='sigmoid')</span></span><br><span class="line"><span class="comment"># ])</span></span><br><span class="line"><span class="comment"># vgg16.trainable = False</span></span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">32</span>, <span class="number">5</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>, input_shape=(img_height, img_width, img_channels)),</span><br><span class="line">    layers.MaxPool2D(strides=<span class="number">2</span>, padding=<span class="string">'SAME'</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line"></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, <span class="number">5</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.MaxPool2D(strides=<span class="number">2</span>, padding=<span class="string">'SAME'</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    </span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, padding=<span class="string">'SAME'</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.MaxPool2D(strides=<span class="number">2</span>, padding=<span class="string">'SAME'</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line"></span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用Adam优化器，对比了RMSProp，Adam收敛速度快一些</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.train.AdamOptimizer(learning_rate),</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'acc'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里调用了callback，保存checkpoint，monitor和save_best_only保证了只在val_loss减小的情况下保存模型参数，period指定了保存的时机，每5个epoch保存一次</span></span><br><span class="line">MODEL_DIR = <span class="string">'./model/'</span></span><br><span class="line">checkpoint_path = MODEL_DIR + <span class="string">"cp-&#123;epoch:04d&#125;.ckpt"</span></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, </span><br><span class="line">                                                monitor=<span class="string">'val_loss'</span>,</span><br><span class="line">                                                save_best_only=<span class="literal">True</span>,</span><br><span class="line">                                                verbose=<span class="number">1</span>, </span><br><span class="line">                                                save_weights_only=<span class="literal">True</span>, </span><br><span class="line">                                                period=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>开始训练，测试，保存最终结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中途停止可以使用下面这行重新加载参数，cp-0015视具体情况修改</span></span><br><span class="line"><span class="comment"># model.load_weights('./model/cp-0015.ckpt')</span></span><br><span class="line"></span><br><span class="line">model.fit(</span><br><span class="line">    image_input_fn(</span><br><span class="line">        train_files, </span><br><span class="line">        train_labels,</span><br><span class="line">        shuffle=<span class="literal">True</span>, </span><br><span class="line">        repeat_count=epochs,</span><br><span class="line">        batch_size=batch_size), </span><br><span class="line">    validation_data=image_input_fn(</span><br><span class="line">        eval_files,</span><br><span class="line">        eval_labels,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        repeat_count=epochs,</span><br><span class="line">        batch_size=<span class="number">50</span>), <span class="comment"># batch_size * validation_steps应当等于验证集大小</span></span><br><span class="line">    epochs=epochs,</span><br><span class="line">    steps_per_epoch=steps_per_epoch,</span><br><span class="line">    validation_steps=<span class="number">20</span>,</span><br><span class="line">    callbacks=[cp_callback])</span><br><span class="line"></span><br><span class="line">result = model.predict(</span><br><span class="line">    image_input_fn(</span><br><span class="line">        test_files,</span><br><span class="line">        test_labels, <span class="comment"># 这个地方是个bug</span></span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        batch_size=<span class="number">50</span>), </span><br><span class="line">        steps=<span class="number">250</span>) <span class="comment"># batch_size * steps应当等于测试集大小，这里调整可以减小内存需要</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据kaggle的经验，限制结果在[0.005, 0.995]之间有助于增加分数</span></span><br><span class="line">path = <span class="string">'./submission1.csv'</span></span><br><span class="line">counter = range(<span class="number">1</span>, len(result) + <span class="number">1</span>)</span><br><span class="line">result = np.array(result, np.float)</span><br><span class="line">result = np.squeeze(result)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">limit</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">0.005</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.005</span></span><br><span class="line">    <span class="keyword">elif</span> x &gt; <span class="number">0.995</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.995</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">'id'</span>: counter, <span class="string">'label'</span>: result&#125;)</span><br><span class="line">df[<span class="string">'label'</span>] = df[<span class="string">'label'</span>].map(limit)</span><br><span class="line"></span><br><span class="line">file = df.to_csv(path_or_buf=<span class="literal">None</span>, index=<span class="literal">None</span>)</span><br><span class="line"><span class="keyword">with</span> tf.gfile.Open(path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(file)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Mission Accomplished!'</span>)</span><br></pre></td></tr></table></figure>
<p>在train完整训练集上，我们使用自定义model训练40轮后得到的分数为</p>
<blockquote>
<p>0.24594</p>
</blockquote>
<p>在train完整训练集上，我们使用VGG16训练10轮后得到的分数为（还有进步空间，前10%大约0.04左右，差距很大）</p>
<blockquote>
<p>0.21975</p>
</blockquote>
<p>但是使用VGG16时有一个明显的问题，设置VGG16模型的参数不参与训练，但是每一次迭代都在计算这一层，也就是说我们浪费了很多时间重复计算。所以接下来我们考虑先使用VGG16或者其他模型对训练集图片生成新的特征向量，再对特征向量建立输出，这样就只需要计算一次VGG16层。</p>
<h3 id="24-使用预训练模型fine-tuning完成猫狗识别"><a class="markdownIt-Anchor" href="#24-使用预训练模型fine-tuning完成猫狗识别"></a> 2.4 使用预训练模型fine-tuning完成猫狗识别</h3>
<p>参考：</p>
<blockquote>
<p><a href="https://www.jianshu.com/p/1bc2abe88388" target="_blank" rel="noopener">Kaggle猫狗大战准确率Top 2%webapp部署</a></p>
</blockquote>
<p>代码根据参考做了修改和完善，补充了一些忽略掉的地方</p>
<p>首先，需要移动图片文件</p>
<p>原始图片路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dogvscat:</span><br><span class="line">    train:</span><br><span class="line">        cat.0.jpg</span><br><span class="line">        cat.1.jpg</span><br><span class="line">        ...</span><br><span class="line">        dog.0.jpg</span><br><span class="line">        ...</span><br><span class="line">    test:</span><br><span class="line">        1.jpg</span><br><span class="line">        2.jpg</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>需要变成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dogvscat:</span><br><span class="line">    img_train:</span><br><span class="line">        cat:</span><br><span class="line">            cat.0.jpg</span><br><span class="line">            ...</span><br><span class="line">        dog:</span><br><span class="line">            dog.0.jpg</span><br><span class="line">            ...</span><br><span class="line">    img_test:</span><br><span class="line">        test:</span><br><span class="line">            1.jpg</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>
<p>test数据很简单，复制一下就行了，对于train数据来说，需要将dog和cat分别放在各自的文件夹中，这里很简单，用<code>shutil.copyfile</code>拷贝就行了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">path = <span class="string">'train'</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">12500</span>):</span><br><span class="line">    name = <span class="string">'dog.&#123;&#125;.jpg'</span>.format(i)</span><br><span class="line">    src = os.path.join(path, name)</span><br><span class="line">    dst = os.path.join(os.path.join(<span class="string">'img_train'</span>, <span class="string">'dog'</span>), name)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">12500</span>):</span><br><span class="line">    name = <span class="string">'cat.&#123;&#125;.jpg'</span>.format(i)</span><br><span class="line">    src = os.path.join(path, name)</span><br><span class="line">    dst = os.path.join(os.path.join(<span class="string">'img_train'</span>, <span class="string">'cat'</span>), name)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>
<p>然后使用<code>ImageDataGenerator</code>和与训练好的模型生成特征向量并保存为<code>.h5</code>文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""使用预训练好的模型inception_v3，resnet50，mobilenet_v2或者其他模型也可以，单个模型也可以"""</span></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> inception_v3</span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> resnet50</span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> mobilenet_v2</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_gap</span><span class="params">(MODEL, image_size, preprocess_input)</span>:</span></span><br><span class="line">    width = image_size[<span class="number">0</span>]</span><br><span class="line">    height = image_size[<span class="number">1</span>]</span><br><span class="line">    input_tensor = keras.Input((height, width, <span class="number">3</span>))</span><br><span class="line">    x = input_tensor</span><br><span class="line">    <span class="comment"># include_top为False表示不需要最后的全连接层做预测，对于最后的数据使用avg池化处理</span></span><br><span class="line">    base_model = MODEL(input_tensor=x, weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>, pooling=<span class="string">'avg'</span>)</span><br><span class="line">    model = keras.Model(inputs=base_model.input, outputs=base_model.output)</span><br><span class="line">    <span class="comment"># ImageDataGenerator需要对数据进行预处理，不同的模型预处理方式不同，比如可能需要减去均值等等，我们这里直接传入模型自带的preprocess_input方法</span></span><br><span class="line">    gen = ImageDataGenerator(preprocessing_function=preprocess_input)</span><br><span class="line">    <span class="comment"># flow_from_directory第一个参数表示图片路径，会自动寻找分类，这里指定classes=['cat', 'dog']，也就是cat标签为0，dog标签为1，class_mode='sparse'表示使用数字作为标签而不是onehot变量，batch_size视内存决定</span></span><br><span class="line">    train_generator = gen.flow_from_directory(<span class="string">"img_train"</span>, image_size, shuffle=<span class="literal">False</span>, classes=[<span class="string">'cat'</span>, <span class="string">'dog'</span>], class_mode=<span class="string">'sparse'</span>,</span><br><span class="line">                                              batch_size=<span class="number">50</span>)</span><br><span class="line">    <span class="comment"># 同理，test文件夹不需要标签，但是也必须放在test文件夹下，表示标签数量为1，flow_from_directory读取文件的方式是os.listdir()，文件名顺序与实际读取顺序不同，所以是个伏笔，需要记录这个信息</span></span><br><span class="line">    test_generator = gen.flow_from_directory(<span class="string">"img_test"</span>, image_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             batch_size=<span class="number">50</span>, class_mode=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 这里我处理了test数据的文件名，因为kaggle的结果是按照文件名顺序排序的，我们必须最后将预测结果排序后再上传</span></span><br><span class="line">    filenames = test_generator.filenames</span><br><span class="line">    index = [int(re.split(<span class="string">'[/.]'</span>, name)[<span class="number">1</span>]) <span class="keyword">for</span> name <span class="keyword">in</span> filenames]</span><br><span class="line">    <span class="comment"># compile是无效的，但是不调用无法执行predict_generator</span></span><br><span class="line">    model.compile(</span><br><span class="line">        loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">        optimizer=<span class="string">'adam'</span>,</span><br><span class="line">        metrics=[<span class="string">'acc'</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    train = model.predict_generator(train_generator, verbose=<span class="number">1</span>)</span><br><span class="line">    test = model.predict_generator(test_generator, verbose=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 将结果写入h5文件中，注意保存了4种数据，这里MODEL.__name__是无效的，始终为wrapper，所以后面不能同时执行</span></span><br><span class="line">    <span class="keyword">with</span> h5py.File(<span class="string">"gap_%s.h5"</span>%MODEL.__name__) <span class="keyword">as</span> h:</span><br><span class="line">        h.create_dataset(<span class="string">"train"</span>, data=train)</span><br><span class="line">        h.create_dataset(<span class="string">"test"</span>, data=test)</span><br><span class="line">        h.create_dataset(<span class="string">"label"</span>, data=train_generator.classes)</span><br><span class="line">        h.create_dataset(<span class="string">"index"</span>, data=index)</span><br><span class="line"><span class="comment"># 每次执行一个模型的特征映射需要手动修改文件名</span></span><br><span class="line">write_gap(inception_v3.InceptionV3, (<span class="number">299</span>, <span class="number">299</span>), inception_v3.preprocess_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># write_gap(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># write_gap(mobilenet_v2.MobileNetV2, (224, 224), mobilenet_v2.preprocess_input)</span></span><br></pre></td></tr></table></figure>
<p>可以使用以下代码测试<code>.h5</code>文件是否正确</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = []</span><br><span class="line">y_train = []</span><br><span class="line">x_test = []</span><br><span class="line">x_index = []</span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'gap_MobileNetV2.h5'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> h:</span><br><span class="line">    x_train.append(np.array(h[<span class="string">'train'</span>]))</span><br><span class="line">    x_test.append(np.array(h[<span class="string">'test'</span>]))</span><br><span class="line">    y_train = np.array(h[<span class="string">'label'</span>])</span><br><span class="line">    x_index = np.array(h[<span class="string">'index'</span>])</span><br><span class="line"></span><br><span class="line">x_train = np.array(x_train)</span><br><span class="line">x_test = np.array(x_test)</span><br><span class="line"></span><br><span class="line">print(x_train.shape, x_test.shape, y_train.shape, x_index.shape)</span><br><span class="line">print(x_train[<span class="number">0</span>], y_train[<span class="number">0</span>])</span><br><span class="line">print(x_index[:<span class="number">10</span>], x_test[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>这样我们得到了三个<code>.h5</code>文件，<code>gap_MobileNetV2.h5, gap_InceptionV3.h5, gap_ResNet50.h5</code>，然后读取数据，重新构建模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 这里在mac上如果需要使用三个模型需要设置这个环境变量，不然报错</span></span><br><span class="line"><span class="comment"># OMP: Error #15: Initializing libomp.dylib, but found libiomp5.dylib already initialized.</span></span><br><span class="line">os.environ[<span class="string">"KMP_DUPLICATE_LIB_OK"</span>]=<span class="string">"TRUE"</span></span><br><span class="line"></span><br><span class="line">x_train = []</span><br><span class="line">y_train = []</span><br><span class="line">x_test = []</span><br><span class="line">x_index = []</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> [<span class="string">'gap_InceptionV3.h5'</span>, <span class="string">'gap_ResNet50.h5'</span>, <span class="string">'gap_MobileNetV2.h5'</span>]:</span><br><span class="line">    <span class="keyword">with</span> h5py.File(filename, <span class="string">'r'</span>) <span class="keyword">as</span> h:</span><br><span class="line">        x_train.append(np.array(h[<span class="string">'train'</span>]))</span><br><span class="line">        x_test.append(np.array(h[<span class="string">'test'</span>]))</span><br><span class="line">        y_train = np.array(h[<span class="string">'label'</span>])</span><br><span class="line">        x_index = np.array(h[<span class="string">'index'</span>])</span><br><span class="line"></span><br><span class="line">x_train = np.concatenate(x_train, axis=<span class="number">1</span>)</span><br><span class="line">x_test = np.concatenate(x_test, axis=<span class="number">1</span>)</span><br><span class="line">y_train = np.array(y_train)</span><br><span class="line">x_index = np.array(x_index)</span><br><span class="line">print(x_train.shape, x_test.shape, y_train.shape, x_index.shape)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unison_shuffled_copies</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    a = np.array(a)</span><br><span class="line">    b = np.array(b)</span><br><span class="line">    <span class="keyword">assert</span> len(a) == len(b)</span><br><span class="line">    p = np.random.permutation(len(a))</span><br><span class="line">    <span class="keyword">return</span> a[p], b[p]</span><br><span class="line"></span><br><span class="line">x_train, y_train = unison_shuffled_copies(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型很简单，将三个特征向量拼接起来，然后dropout，最后输出sigmoid</span></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>, input_shape=(x_train.shape[<span class="number">-1</span>],)),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    optimizer=tf.train.AdamOptimizer(),</span><br><span class="line">    metrics=[<span class="string">'acc'</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.fit(</span><br><span class="line">    x=x_train,</span><br><span class="line">    y=y_train,</span><br><span class="line">    batch_size=<span class="number">128</span>,</span><br><span class="line">    epochs=<span class="number">8</span>,</span><br><span class="line">    validation_split=<span class="number">0.2</span>,</span><br><span class="line">    callbacks=[keras.callbacks.TensorBoard(log_dir=<span class="string">'./log'</span>)]</span><br><span class="line">)</span><br><span class="line">model.save(<span class="string">'model.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line">result = model.predict(x_test)</span><br><span class="line"></span><br><span class="line">path = <span class="string">'./submission.csv'</span></span><br><span class="line">counter = x_index</span><br><span class="line">result = np.array(result, np.float)</span><br><span class="line">result = np.squeeze(result)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">limit</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">0.005</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.005</span></span><br><span class="line">    <span class="keyword">elif</span> x &gt; <span class="number">0.995</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.995</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">'id'</span>: counter, <span class="string">'label'</span>: result&#125;)</span><br><span class="line">df[<span class="string">'label'</span>] = df[<span class="string">'label'</span>].map(limit)</span><br><span class="line">df = df.sort_values(by=<span class="string">'id'</span>) <span class="comment"># 这里对应上文提到的，根据文件名排序</span></span><br><span class="line">file = df.to_csv(path_or_buf=<span class="literal">None</span>, index=<span class="literal">None</span>)</span><br><span class="line"><span class="keyword">with</span> tf.gfile.Open(path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(file)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Mission Accomplished!'</span>)</span><br></pre></td></tr></table></figure>
<p>kaggle分数：</p>
<blockquote>
<p>0.04071</p>
</blockquote>
<h3 id="25-自定义estimator-cifar10识别"><a class="markdownIt-Anchor" href="#25-自定义estimator-cifar10识别"></a> 2.5 自定义Estimator-CIFAR10识别</h3>
<p>参考：</p>
<blockquote>
<p><a href="https://www.tensorflow.org/tutorials/images/deep_cnn" target="_blank" rel="noopener">高级卷积神经网络</a><br />
<a href="https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator" target="_blank" rel="noopener">CIFAR-10 ResNet</a></p>
</blockquote>
<p><strong>首先分析一下Google官网的CIFAR-10源码</strong></p>
<p><a href="http://zhoutao822.coding.me/2018/12/13/TensorFlow-CIFAR10/"><code>TnesorFlow-CIFAR10</code></a></p>
<p><strong>然后开始修改代码适配自己的环境</strong></p>
<p><code>generate_cifar10_tfrecords.py</code>少量修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="string">"""根据cifar10数据集生成TFRecords文件</span></span><br><span class="line"><span class="string">版本：</span></span><br><span class="line"><span class="string">    TensorFlow：1.12</span></span><br><span class="line"><span class="string">    Python：3.6.7</span></span><br><span class="line"><span class="string">使用keras.datasets.cifar10.load_data()获得数据，训练集中划分后20%作为验证集，</span></span><br><span class="line"><span class="string">通过TFRecordWriter写入到三个文件中：train.tfrecords, validation.tfrecords, </span></span><br><span class="line"><span class="string">eval.tfrecords，运行时参数data_dir指定生成文件的路径。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'data_dir'</span>, <span class="string">'./cifar10'</span>, <span class="string">'Directory to generate tfrecords to.'</span>)</span><br><span class="line">FILE_NAMES = [<span class="string">'train'</span>, <span class="string">'validation'</span>, <span class="string">'eval'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_int64_feature</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_bytes_feature</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_tfrecord</span><span class="params">(x, y, output_file)</span>:</span></span><br><span class="line">    <span class="string">"""生成tfrecords"""</span></span><br><span class="line">    <span class="keyword">with</span> tf.io.TFRecordWriter(output_file) <span class="keyword">as</span> writer:</span><br><span class="line">        data_length = len(y)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(data_length):</span><br><span class="line">            example = tf.train.Example(features=tf.train.Features(</span><br><span class="line">                feature=&#123;</span><br><span class="line">                    <span class="comment"># 通过keras获得的数据集的image是uint8类型的数据</span></span><br><span class="line">                    <span class="string">'image'</span>: _bytes_feature(x[i].tobytes()),</span><br><span class="line">                    <span class="comment"># 通过keras获得的数据集的label是[xxx, 1]的形状，类型int32，</span></span><br><span class="line">                    <span class="comment"># 需要y[i, 0]获得标签数值，类型转换为int64，</span></span><br><span class="line">                    <span class="comment"># tfrecords只支持Int64List，没有Int32List</span></span><br><span class="line">                    <span class="string">'label'</span>: _int64_feature(y[i, <span class="number">0</span>].astype(np.int64))</span><br><span class="line">                &#125;))</span><br><span class="line">            writer.write(example.SerializeToString())</span><br><span class="line">    print(<span class="string">'Generate &#123;&#125; success!'</span>.format(output_file))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(data_dir)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        data_dir：tfrecords文件保存路径</span></span><br><span class="line"><span class="string">    功能：</span></span><br><span class="line"><span class="string">        主函数，包括生成文件夹，获取数据，划分数据，生成tfrecords文件</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(data_dir):</span><br><span class="line">        os.mkdir(data_dir)</span><br><span class="line">    print(<span class="string">'Start to generate tfrecords in &#123;&#125;.'</span>.format(data_dir))</span><br><span class="line">    <span class="comment"># 调用keras.datasets.cifar10.load_data()获得数据</span></span><br><span class="line">    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()</span><br><span class="line">    <span class="comment"># 这里划分前80%的数据做训练集，20%验证集，理论上要shuffle，</span></span><br><span class="line">    <span class="comment"># 这里我感觉不shuffle也行</span></span><br><span class="line">    split_index = int(len(y_train) * <span class="number">0.8</span>)</span><br><span class="line">    <span class="keyword">assert</span> len(x_train) == len(y_train)</span><br><span class="line">    val_data = x_train[split_index:], y_train[split_index:]</span><br><span class="line">    train_data = x_train[:split_index], y_train[:split_index]</span><br><span class="line">    eval_data = x_test, y_test</span><br><span class="line">    <span class="keyword">for</span> mode, data <span class="keyword">in</span> zip(FILE_NAMES, [train_data, val_data, eval_data]):</span><br><span class="line">        output_file = os.path.join(data_dir, mode + <span class="string">'.tfrecords'</span>)</span><br><span class="line">        x, y = data</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            os.remove(output_file)</span><br><span class="line">        <span class="keyword">except</span> OSError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        convert_to_tfrecord(x, y, output_file)</span><br><span class="line">    print(<span class="string">'Done!'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 通过tensorflow的flags产生运行时参数，简单一些</span></span><br><span class="line">    main(FLAGS.data_dir)</span><br></pre></td></tr></table></figure>
<p><code>cifar10.py</code>少量修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="string">"""生成CIFAR10 Dataset</span></span><br><span class="line"><span class="string">版本：</span></span><br><span class="line"><span class="string">    TensorFlow：1.12</span></span><br><span class="line"><span class="string">    Python：3.6.7</span></span><br><span class="line"><span class="string">读取tfrecords文件，对图片和标签的数据类型进行调整，对图片进行扰乱处理，比如裁剪、</span></span><br><span class="line"><span class="string">亮度调整、对比度调整和翻转等操作，shuffle和batch，make_batch返回一个batch的数据，</span></span><br><span class="line"><span class="string">此部分代码改动较少。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">HEIGHT = <span class="number">32</span></span><br><span class="line">WIDTH = <span class="number">32</span></span><br><span class="line">DEPTH = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cifar10DataSet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""通过一个类来管理dataset"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_dir, subset=<span class="string">'train'</span>, use_distortion=True)</span>:</span></span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.subset = subset</span><br><span class="line">        self.use_distortion = use_distortion</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_filenames</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.subset <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'validation'</span>, <span class="string">'eval'</span>]:</span><br><span class="line">            <span class="keyword">return</span> [os.path.join(self.data_dir, self.subset + <span class="string">'.tfrecords'</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Invalid data subset &#123;&#125;'</span>.format(self.subset))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(self, example)</span>:</span></span><br><span class="line">        <span class="string">"""读取tfrecords文件，类型转换，shape调整"""</span></span><br><span class="line">        features = tf.parse_single_example(</span><br><span class="line">            example, </span><br><span class="line">            features=&#123;</span><br><span class="line">                <span class="string">'image'</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">                <span class="string">'label'</span>: tf.FixedLenFeature([], tf.int64)</span><br><span class="line">            &#125;)</span><br><span class="line">        image = tf.decode_raw(features[<span class="string">'image'</span>], tf.uint8)</span><br><span class="line">        image.set_shape([DEPTH * HEIGHT * WIDTH])</span><br><span class="line"></span><br><span class="line">        image = tf.cast(</span><br><span class="line">            tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]),</span><br><span class="line">            tf.float32)</span><br><span class="line">        label = tf.cast(features[<span class="string">'label'</span>], tf.int32)</span><br><span class="line"></span><br><span class="line">        image = self.preprocess(image)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        <span class="string">"""对train数据集进行扰乱，包括裁剪、亮度调整、对比度调整和翻转等操作"""</span></span><br><span class="line">        <span class="keyword">if</span> self.subset == <span class="string">'train'</span> <span class="keyword">and</span> self.use_distortion:</span><br><span class="line">            image = tf.image.resize_image_with_crop_or_pad(image, <span class="number">40</span>, <span class="number">40</span>)</span><br><span class="line">            image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH]) <span class="comment"># 裁剪</span></span><br><span class="line">            image = tf.image.random_flip_left_right(image) <span class="comment"># 左右翻转</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_brightness(image, max_delta=10) # 亮度</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_contrast(image, lower=0.2, upper=1.8) # 对比度</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_hue(image, max_delta=0.1) # 色相</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_flip_up_down(image) # 上下翻转</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_saturation(image, 0, 5) # 饱和度</span></span><br><span class="line">            <span class="comment"># image = tf.image.random_jpeg_quality(image, 50, 90) # 噪声，jpeg质量</span></span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_batch</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        <span class="string">"""通过TFRecordDataset读取文件，shuffle和batch数据集，返回一个batch的数据"""</span></span><br><span class="line">        filenames = self.get_filenames()</span><br><span class="line">        dataset = tf.data.TFRecordDataset(filenames).repeat()</span><br><span class="line">        <span class="comment"># num_parallel_calls并行处理，加速IO</span></span><br><span class="line">        dataset = dataset.map(</span><br><span class="line">            self.parser, num_parallel_calls=batch_size)</span><br><span class="line">        <span class="comment"># 缓冲池的大小设计</span></span><br><span class="line">        <span class="keyword">if</span> self.subset == <span class="string">'train'</span>:</span><br><span class="line">            min_queue_examples = int(</span><br><span class="line">                Cifar10DataSet.num_examples_per_epoch(self.subset) * <span class="number">0.4</span>)</span><br><span class="line">            dataset = dataset.shuffle(buffer_size=min_queue_examples + <span class="number">3</span> * batch_size)</span><br><span class="line"></span><br><span class="line">        dataset = dataset.batch(batch_size)</span><br><span class="line">        iterator = dataset.make_one_shot_iterator()</span><br><span class="line">        image_batch, label_batch = iterator.get_next()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image_batch, label_batch</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_examples_per_epoch</span><span class="params">(subset=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> subset == <span class="string">'train'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">40000</span> <span class="comment"># 对源码进行了修改</span></span><br><span class="line">        <span class="keyword">elif</span> subset == <span class="string">'validation'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">10000</span></span><br><span class="line">        <span class="keyword">elif</span> subset == <span class="string">'eval'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">10000</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Invalid data subset "%s"'</span> % subset)</span><br></pre></td></tr></table></figure>
<p>通过下面的代码测试<code>Cifar10DataSet</code>是否正确</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line">dataset = cifar10.Cifar10DataSet(<span class="string">'./cifar10'</span>)</span><br><span class="line">data = dataset.make_batch(<span class="number">16</span>)</span><br><span class="line">img, label = sess.run(data)</span><br><span class="line"></span><br><span class="line">print(img.shape, label)</span><br></pre></td></tr></table></figure>
<p><strong>这里我修改成了仅使用CPU训练的模式</strong></p>
<p><code>model_base.py</code>和<code>cifar10_model.py</code>没有修改，<code>cifar10_main_cpu.py</code>大量修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="string">"""使用CPU进行训练的main文件</span></span><br><span class="line"><span class="string">版本：</span></span><br><span class="line"><span class="string">    TensorFlow：1.12</span></span><br><span class="line"><span class="string">    Python：3.6.7</span></span><br><span class="line"><span class="string">定义运行时参数，仅使用CPU进行训练和验证</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">import</span> cifar10_model</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'data_dir'</span>, <span class="string">'./cifar10'</span>, <span class="string">'Directory to generate tfrecords to.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'job_dir'</span>, <span class="string">'./tmp'</span>, <span class="string">'Directory to generate model to.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'train_steps'</span>, <span class="number">1000</span>, <span class="string">'Train steps.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'eval_steps'</span>, <span class="number">100</span>, <span class="string">'Eval steps.'</span>)  <span class="comment"># eval_steps * eval_batch_size最好等于eval数据集大小</span></span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'train_batch_size'</span>, <span class="number">128</span>, <span class="string">'Train batch size.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'eval_batch_size'</span>, <span class="number">100</span>, <span class="string">'Eval batch size.'</span>)    </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_layers'</span>, <span class="number">44</span>, <span class="string">'The number of layers of the model.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'learning_rate'</span>, <span class="number">0.1</span>, <span class="string">'Learning rate value.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'decay_steps'</span>, <span class="number">1000</span>, <span class="string">'The number of learning rate decay steps.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'decay_rate'</span>, <span class="number">0.9</span>, <span class="string">'Decay rate value.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_boolean(</span><br><span class="line">    <span class="string">'use_distortion_for_training'</span>, <span class="literal">True</span>, <span class="string">'If doing image distortion for training.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'batch_norm_decay'</span>, <span class="number">0.997</span>, <span class="string">'Decay for batch norm.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'batch_norm_epsilon'</span>, <span class="number">1e-5</span>, <span class="string">'Epsilon for batch norm.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_inter_threads'</span>, <span class="number">6</span>, <span class="string">'Number of threads to use for inter-op parallelism.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_intra_threads'</span>, <span class="number">6</span>, <span class="string">'Number of threads to use for intra-op parallelism.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_fn</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""返回Estimator的model_fn"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_resnet_model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        返回包含Resnet模型的EstimatorSpec，只有train和evaluate方法，</span></span><br><span class="line"><span class="string">        没有predict方法，优化器使用Adam，learning rate会自动衰减</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            features：一个batch的image数据</span></span><br><span class="line"><span class="string">            labels：一个batch的label数据</span></span><br><span class="line"><span class="string">            mode：调用train还是evaluate</span></span><br><span class="line"><span class="string">            params：其他运行参数</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tf.estimator.EstimatorSpec</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        is_training = (mode == tf.estimator.ModeKeys.TRAIN)</span><br><span class="line">        decay_steps = params[<span class="string">'decay_steps'</span>] <span class="comment"># 学习率衰减的steps</span></span><br><span class="line">        decay_rate = params[<span class="string">'decay_rate'</span>] <span class="comment"># 学习率衰减率</span></span><br><span class="line">        learning_rate = params[<span class="string">'learning_rate'</span>]</span><br><span class="line"></span><br><span class="line">        loss, preds = _calc_fn(</span><br><span class="line">            is_training, features, labels,</span><br><span class="line">            params[<span class="string">'num_layers'</span>], params[<span class="string">'batch_norm_decay'</span>],</span><br><span class="line">            params[<span class="string">'batch_norm_epsilon'</span>])</span><br><span class="line">        <span class="comment"># batch_norm需要更新</span></span><br><span class="line">        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用tf.train.exponential_decay实现学习率衰减，</span></span><br><span class="line">        <span class="comment"># 以默认情况，80000steps后学习率衰减为0.0002，与原始代码近似</span></span><br><span class="line">        learning_rate = tf.train.exponential_decay(</span><br><span class="line">            learning_rate=learning_rate,</span><br><span class="line">            global_step=tf.train.get_global_step(),</span><br><span class="line">            decay_steps=decay_steps,</span><br><span class="line">            decay_rate=decay_rate</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># tensor_to_log是dict类型，且key为tensor的name</span></span><br><span class="line">        avg_loss = tf.reduce_mean(loss)</span><br><span class="line">        avg_loss = tf.identity(avg_loss, name=<span class="string">'loss'</span>)</span><br><span class="line">        tensor_to_log = &#123;<span class="string">'learning_rate'</span>: learning_rate, <span class="string">'loss'</span>: avg_loss&#125;</span><br><span class="line">        logging_hook = tf.train.LoggingTensorHook(</span><br><span class="line">            tensors=tensor_to_log, every_n_iter=<span class="number">100</span>)</span><br><span class="line">        </span><br><span class="line">        counter_hook = tf.train.StepCounterHook(every_n_steps=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        train_hooks = [logging_hook, counter_hook]</span><br><span class="line"></span><br><span class="line">        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line"></span><br><span class="line">        train_op = [</span><br><span class="line">            optimizer.minimize(</span><br><span class="line">                loss, global_step=tf.train.get_global_step())</span><br><span class="line">        ]</span><br><span class="line">        train_op.extend(update_ops)</span><br><span class="line">        train_op = tf.group(*train_op)</span><br><span class="line"></span><br><span class="line">        predictions = &#123;</span><br><span class="line">            <span class="string">'classes'</span>: preds[<span class="string">'classes'</span>],</span><br><span class="line">            <span class="string">'probabilities'</span>: preds[<span class="string">'probabilities'</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        metrics = &#123;</span><br><span class="line">            <span class="string">'accuracy'</span>:</span><br><span class="line">                tf.metrics.accuracy(labels, predictions[<span class="string">'classes'</span>])</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">            mode=mode,</span><br><span class="line">            predictions=predictions,</span><br><span class="line">            loss=loss,</span><br><span class="line">            train_op=train_op,</span><br><span class="line">            training_hooks=train_hooks,</span><br><span class="line">            eval_metric_ops=metrics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> _resnet_model_fn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_fn</span><span class="params">(is_training, feature, label, </span></span></span><br><span class="line"><span class="function"><span class="params">            num_layers, batch_norm_decay, batch_norm_epsilon)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    获取model，简单计算</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        is_training：判断是train还是evaluate</span></span><br><span class="line"><span class="string">        feature：一个batch的image数据</span></span><br><span class="line"><span class="string">        label：一个batch的label数据</span></span><br><span class="line"><span class="string">        num_layers：Resnet层数</span></span><br><span class="line"><span class="string">        batch_norm_decay：Resnet参数</span></span><br><span class="line"><span class="string">        batch_norm_epsilon：Resnet参数</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        loss：一个batch的softmax_cross_entropy</span></span><br><span class="line"><span class="string">        pred：字典类型包括一个batch的标签和概率</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = cifar10_model.ResNetCifar10(</span><br><span class="line">        num_layers,</span><br><span class="line">        batch_norm_decay=batch_norm_decay,</span><br><span class="line">        batch_norm_epsilon=batch_norm_epsilon,</span><br><span class="line">        is_training=is_training,</span><br><span class="line">        data_format=<span class="string">'channels_last'</span>)</span><br><span class="line">    logits = model.forward_pass(feature, input_data_format=<span class="string">'channels_last'</span>)</span><br><span class="line">    pred = &#123;</span><br><span class="line">        <span class="string">'classes'</span>: tf.argmax(input=logits, axis=<span class="number">1</span>),</span><br><span class="line">        <span class="string">'probabilities'</span>: tf.nn.softmax(logits)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    loss = tf.losses.sparse_softmax_cross_entropy(</span><br><span class="line">        logits=logits, labels=label)</span><br><span class="line">    <span class="keyword">return</span> loss, pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_dir,</span></span></span><br><span class="line"><span class="function"><span class="params">            subset,</span></span></span><br><span class="line"><span class="function"><span class="params">            batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">            use_distortion_for_training=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    输入函数，可以用于train数据集合eval数据集</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_dir：tfrecords文件所在的文件夹</span></span><br><span class="line"><span class="string">        subset：判断是train还是evaluate</span></span><br><span class="line"><span class="string">        batch_size：一个batch的大小</span></span><br><span class="line"><span class="string">        use_distortion_for_training：是否对数据进行扰动</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        image_batch：一个batch的image数据</span></span><br><span class="line"><span class="string">        label_batch：一个batch的label数据</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    use_distortion = subset == <span class="string">'train'</span> <span class="keyword">and</span> use_distortion_for_training</span><br><span class="line">    dataset = cifar10.Cifar10DataSet(data_dir, subset, use_distortion)</span><br><span class="line">    image_batch, label_batch = dataset.make_batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> image_batch, label_batch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(flags)</span>:</span></span><br><span class="line">    <span class="comment"># 为了调用多线程运行，需要使用tf.ConfigProto，</span></span><br><span class="line">    <span class="comment"># device_count指定最多使用多少devices，比如CPU，最多仅支持1；</span></span><br><span class="line">    <span class="comment"># 如果有多个GPU，可以指定最多使用其中的多少个，键值对形式</span></span><br><span class="line">    <span class="comment"># intra_op_parallelism_threads 控制运算符op内部的并行</span></span><br><span class="line">    <span class="comment"># inter_op_parallelism_threads 控制多个运算符op之间的并行计算</span></span><br><span class="line">    <span class="comment"># 线程数最好根据CPU的核心数来决定</span></span><br><span class="line">    run_config = tf.ConfigProto(</span><br><span class="line">        device_count=&#123;<span class="string">"CPU"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">        intra_op_parallelism_threads=flags.num_intra_threads,</span><br><span class="line">        inter_op_parallelism_threads=flags.num_inter_threads)</span><br><span class="line">    <span class="comment"># tf.ConfigProto不能直接添加到Estimator中，</span></span><br><span class="line">    <span class="comment"># 需要使用tf.estimator.RunConfig包裹一下，顺便指定模型存储路径model_dir</span></span><br><span class="line">    config = tf.estimator.RunConfig(</span><br><span class="line">        model_dir=flags.job_dir,</span><br><span class="line">        session_config=run_config)</span><br><span class="line">    <span class="comment"># tf.estimator.Estimator的params必须是dict类型</span></span><br><span class="line">    classifier = tf.estimator.Estimator(</span><br><span class="line">        model_fn=get_model_fn(),</span><br><span class="line">        config=config,</span><br><span class="line">        params=&#123;</span><br><span class="line">            <span class="string">'decay_steps'</span>: flags.decay_steps,</span><br><span class="line">            <span class="string">'decay_rate'</span>: flags.decay_rate,</span><br><span class="line">            <span class="string">'num_layers'</span>: flags.num_layers,</span><br><span class="line">            <span class="string">'batch_norm_decay'</span>: flags.batch_norm_decay,</span><br><span class="line">            <span class="string">'batch_norm_epsilon'</span>: flags.batch_norm_epsilon,</span><br><span class="line">            <span class="string">'train_batch_size'</span>: flags.train_batch_size,</span><br><span class="line">            <span class="string">'learning_rate'</span>: flags.learning_rate</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="comment"># 循环多次以观察eval的变化，防止过拟合</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">        classifier.train(input_fn=<span class="keyword">lambda</span>: input_fn(</span><br><span class="line">            flags.data_dir, <span class="string">'train'</span>, flags.train_batch_size), </span><br><span class="line">            steps=flags.train_steps)</span><br><span class="line">        classifier.evaluate(input_fn=<span class="keyword">lambda</span>: input_fn(</span><br><span class="line">            flags.data_dir, <span class="string">'eval'</span>, flags.eval_batch_size),</span><br><span class="line">            steps=flags.eval_steps)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(FLAGS.data_dir):</span><br><span class="line">        os.mkdir(FLAGS.data_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(FLAGS.job_dir):</span><br><span class="line">        os.mkdir(FLAGS.job_dir)        </span><br><span class="line">    main(FLAGS)</span><br></pre></td></tr></table></figure>
<p>首先通过<code>generate_cifar10_tfrecords.py</code>生成tfrecords文件，然后运行<code>cifar10_main_cpu.py</code>，同时可以自行指定各种参数，也可以使用默认值。</p>
<hr />
<p>修改代码以适配多GPU环境，<code>cifar10_main_gpu.py</code>在源码的基础上小作修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="string">"""使用GPU进行训练的main文件，包括分布式，实际功能未测试</span></span><br><span class="line"><span class="string">版本：</span></span><br><span class="line"><span class="string">    TensorFlow：1.12</span></span><br><span class="line"><span class="string">    Python：3.6.7</span></span><br><span class="line"><span class="string">定义运行时参数，仅使用GPU进行训练和验证</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">import</span> cifar10_model</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'data_dir'</span>, <span class="string">'./cifar10'</span>, <span class="string">'Directory to generate tfrecords to.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'job_dir'</span>, <span class="string">'./tmp1'</span>, <span class="string">'Directory to generate model to.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'variable_strategy'</span>, <span class="string">'CPU'</span>, <span class="string">'Where to locate variable operations'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'train_steps'</span>, <span class="number">20000</span>, <span class="string">'Train steps.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_gpus'</span>, <span class="number">0</span>, <span class="string">'The number of gpus used. Uses only CPU if set to 0.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'eval_steps'</span>, <span class="number">100</span>, <span class="string">'Eval steps.'</span>)  <span class="comment"># eval_steps * eval_batch_size最好等于eval数据集大小</span></span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'train_batch_size'</span>, <span class="number">128</span>, <span class="string">'Train batch size.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'eval_batch_size'</span>, <span class="number">100</span>, <span class="string">'Eval batch size.'</span>)    </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_layers'</span>, <span class="number">44</span>, <span class="string">'The number of layers of the model.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'learning_rate'</span>, <span class="number">0.1</span>, <span class="string">'Learning rate value.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'weight_decay'</span>, <span class="number">2e-4</span>, <span class="string">'Weight decay for convolutions.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'decay_steps'</span>, <span class="number">2000</span>, <span class="string">'The number of learning rate decay steps.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'decay_rate'</span>, <span class="number">0.96</span>, <span class="string">'Decay rate value.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    <span class="string">'data_format'</span>, <span class="literal">None</span>, <span class="string">"""If not set, the data format best for the training device is used. </span></span><br><span class="line"><span class="string">    Allowed values: channels_first (NCHW) channels_last (NHWC)."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(</span><br><span class="line">    <span class="string">'log_device_placement'</span>, <span class="literal">False</span>, <span class="string">'Whether to log device placement.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_boolean(</span><br><span class="line">    <span class="string">'sync'</span>, <span class="literal">False</span>, <span class="string">'If present when running in a distributed environment will run on sync mode.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_boolean(</span><br><span class="line">    <span class="string">'use_distortion_for_training'</span>, <span class="literal">True</span>, <span class="string">'If doing image distortion for training.'</span>) </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'batch_norm_decay'</span>, <span class="number">0.997</span>, <span class="string">'Decay for batch norm.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_float(</span><br><span class="line">    <span class="string">'batch_norm_epsilon'</span>, <span class="number">1e-5</span>, <span class="string">'Epsilon for batch norm.'</span>)   </span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_inter_threads'</span>, <span class="number">6</span>, <span class="string">'Number of threads to use for inter-op parallelism.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(</span><br><span class="line">    <span class="string">'num_intra_threads'</span>, <span class="number">6</span>, <span class="string">'Number of threads to use for intra-op parallelism.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model_fn</span><span class="params">(num_gpus, variable_strategy, num_workers)</span>:</span></span><br><span class="line">    <span class="string">"""返回Estimator的model_fn"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_resnet_model_fn</span><span class="params">(features, labels, mode, params)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        返回包含Resnet模型的EstimatorSpec，只有train和evaluate方法，</span></span><br><span class="line"><span class="string">        没有predict方法，优化器使用Adam，learning rate会自动衰减</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            features：一个batch的image数据</span></span><br><span class="line"><span class="string">            labels：一个batch的label数据</span></span><br><span class="line"><span class="string">            mode：调用train还是evaluate</span></span><br><span class="line"><span class="string">            params：其他运行参数</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tf.estimator.EstimatorSpec</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        is_training = (mode == tf.estimator.ModeKeys.TRAIN)</span><br><span class="line">        decay_steps = params[<span class="string">'decay_steps'</span>] <span class="comment"># 学习率衰减的steps</span></span><br><span class="line">        decay_rate = params[<span class="string">'decay_rate'</span>] <span class="comment"># 学习率衰减率</span></span><br><span class="line">        learning_rate = params[<span class="string">'learning_rate'</span>]</span><br><span class="line">        weight_decay = params[<span class="string">'weight_decay'</span>]</span><br><span class="line">        <span class="comment"># 多GPU需要分别计算不同设备的loss和梯度，再综合起来</span></span><br><span class="line">        tower_features = features</span><br><span class="line">        tower_labels = labels</span><br><span class="line">        tower_losses = []</span><br><span class="line">        tower_gradvars = []</span><br><span class="line">        tower_preds = []</span><br><span class="line"></span><br><span class="line">        data_format = params[<span class="string">'data_format'</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data_format:</span><br><span class="line">            <span class="keyword">if</span> num_gpus == <span class="number">0</span>:</span><br><span class="line">                data_format = <span class="string">'channels_last'</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                data_format = <span class="string">'channels_first'</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_gpus == <span class="number">0</span>:</span><br><span class="line">            num_devices = <span class="number">1</span></span><br><span class="line">            device_type = <span class="string">'cpu'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            num_devices = num_gpus</span><br><span class="line">            device_type = <span class="string">'gpu'</span></span><br><span class="line">        <span class="comment"># Todo GPU部分代码没有测试，不知道是不是对的</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_devices):</span><br><span class="line">            worker_device = <span class="string">'/&#123;&#125;:&#123;&#125;'</span>.format(device_type, i)</span><br><span class="line">            <span class="keyword">if</span> variable_strategy == <span class="string">'CPU'</span>:</span><br><span class="line">                device_setter = tf.train.replica_device_setter(</span><br><span class="line">                    worker_device=worker_device)</span><br><span class="line">            <span class="keyword">elif</span> variable_strategy == <span class="string">'GPU'</span>:</span><br><span class="line">                device_setter = tf.train.replica_device_setter(</span><br><span class="line">                    worker_device=worker_device,</span><br><span class="line">                    ps_strategy=tf.contrib.training.GreedyLoadBalancingStrategy(</span><br><span class="line">                        num_gpus, tf.contrib.training.byte_size_load_fn))</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">'resnet'</span>, reuse=bool(i != <span class="number">0</span>)):</span><br><span class="line">                <span class="keyword">with</span> tf.name_scope(<span class="string">'tower_%d'</span> % i) <span class="keyword">as</span> name_scope:</span><br><span class="line">                    <span class="keyword">with</span> tf.device(device_setter):</span><br><span class="line">                        loss, gradvars, preds = _calc_fn(</span><br><span class="line">                            is_training, weight_decay, tower_features[i], </span><br><span class="line">                            tower_labels[i], data_format, params[<span class="string">'num_layers'</span>], </span><br><span class="line">                            params[<span class="string">'batch_norm_decay'</span>], params[<span class="string">'batch_norm_epsilon'</span>])</span><br><span class="line">                        tower_losses.append(loss)</span><br><span class="line">                        tower_gradvars.append(gradvars)</span><br><span class="line">                        tower_preds.append(preds)</span><br><span class="line">                        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                            <span class="comment"># batch_norm需要更新</span></span><br><span class="line">                            update_ops = tf.get_collection(</span><br><span class="line">                                tf.GraphKeys.UPDATE_OPS, name_scope)</span><br><span class="line">        </span><br><span class="line">        gradvars = []</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'gradient_averaging'</span>):</span><br><span class="line">            all_grads = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> grad, var <span class="keyword">in</span> itertools.chain(*tower_gradvars):</span><br><span class="line">                <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    all_grads.setdefault(var, []).append(grad)</span><br><span class="line">            <span class="keyword">for</span> var, grads <span class="keyword">in</span> all_grads.items():</span><br><span class="line">                <span class="keyword">with</span> tf.device(var.device):</span><br><span class="line">                    <span class="keyword">if</span> len(grads) == <span class="number">1</span>:</span><br><span class="line">                        avg_grad = grads[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        avg_grad = tf.multiply(tf.add_n(grads), <span class="number">1.</span> / len(grads))</span><br><span class="line">                gradvars.append((avg_grad, var))</span><br><span class="line"></span><br><span class="line">        consolidation_device = <span class="string">'/gpu:0'</span> <span class="keyword">if</span> variable_strategy == <span class="string">'GPU'</span> <span class="keyword">else</span> <span class="string">'/cpu:0'</span></span><br><span class="line">        <span class="keyword">with</span> tf.device(consolidation_device):</span><br><span class="line">            <span class="comment"># 使用tf.train.exponential_decay实现学习率衰减</span></span><br><span class="line">            learning_rate = tf.train.exponential_decay(</span><br><span class="line">                learning_rate=learning_rate,</span><br><span class="line">                global_step=tf.train.get_global_step(),</span><br><span class="line">                decay_steps=decay_steps,</span><br><span class="line">                decay_rate=decay_rate</span><br><span class="line">            )</span><br><span class="line">            loss = tf.reduce_mean(tower_losses, name=<span class="string">'loss'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># tensor_to_log是dict类型，且key为tensor的name</span></span><br><span class="line">            tensor_to_log = &#123;<span class="string">'learning_rate'</span>: learning_rate, <span class="string">'loss'</span>: loss&#125;</span><br><span class="line">            logging_hook = tf.train.LoggingTensorHook(</span><br><span class="line">                tensors=tensor_to_log, every_n_iter=<span class="number">100</span>)</span><br><span class="line">        </span><br><span class="line">            counter_hook = tf.train.StepCounterHook(every_n_steps=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">            train_hooks = [logging_hook, counter_hook]</span><br><span class="line"></span><br><span class="line">            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">            <span class="comment"># Todo，分布式代码没有测试</span></span><br><span class="line">            <span class="keyword">if</span> params[<span class="string">'sync'</span>]:</span><br><span class="line">                optimizer = tf.train.SyncReplicasOptimizer(</span><br><span class="line">                    optimizer, replicas_to_aggregate=num_workers)</span><br><span class="line">                sync_replicas_hook = optimizer.make_session_run_hook(params[<span class="string">'is_chief'</span>])</span><br><span class="line">                train_hooks.append(sync_replicas_hook)</span><br><span class="line">            train_op = [</span><br><span class="line">                optimizer.apply_gradients(</span><br><span class="line">                    gradvars, global_step=tf.train.get_global_step())</span><br><span class="line">            ]</span><br><span class="line">            train_op.extend(update_ops)</span><br><span class="line">            train_op = tf.group(*train_op)</span><br><span class="line"></span><br><span class="line">            predictions = &#123;</span><br><span class="line">                <span class="string">'classes'</span>: </span><br><span class="line">                    tf.concat([p[<span class="string">'classes'</span>] <span class="keyword">for</span> p <span class="keyword">in</span> tower_preds], axis=<span class="number">0</span>),</span><br><span class="line">                <span class="string">'probabilities'</span>: </span><br><span class="line">                    tf.concat([p[<span class="string">'probabilities'</span>] <span class="keyword">for</span> p <span class="keyword">in</span> tower_preds], axis=<span class="number">0</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            stacked_labels = tf.concat(labels, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            metrics = &#123;</span><br><span class="line">                <span class="string">'accuracy'</span>:</span><br><span class="line">                    tf.metrics.accuracy(stacked_labels, predictions[<span class="string">'classes'</span>])</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">            mode=mode,</span><br><span class="line">            predictions=predictions,</span><br><span class="line">            loss=loss,</span><br><span class="line">            train_op=train_op,</span><br><span class="line">            training_hooks=train_hooks,</span><br><span class="line">            eval_metric_ops=metrics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> _resnet_model_fn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_fn</span><span class="params">(is_training, weight_decay, feature, label, data_format,</span></span></span><br><span class="line"><span class="function"><span class="params">            num_layers, batch_norm_decay, batch_norm_epsilon)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    获取model，简单计算</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        is_training：判断是train还是evaluate</span></span><br><span class="line"><span class="string">        weight_decay：l2损失系数</span></span><br><span class="line"><span class="string">        feature：一个batch的image数据</span></span><br><span class="line"><span class="string">        label：一个batch的label数据</span></span><br><span class="line"><span class="string">        data_format：channels_last (NHWC) or channels_first (NCHW)</span></span><br><span class="line"><span class="string">        num_layers：Resnet层数</span></span><br><span class="line"><span class="string">        batch_norm_decay：Resnet参数</span></span><br><span class="line"><span class="string">        batch_norm_epsilon：Resnet参数</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        loss：一个batch的softmax_cross_entropy</span></span><br><span class="line"><span class="string">        pred：字典类型包括一个batch的标签和概率</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = cifar10_model.ResNetCifar10(</span><br><span class="line">        num_layers,</span><br><span class="line">        batch_norm_decay=batch_norm_decay,</span><br><span class="line">        batch_norm_epsilon=batch_norm_epsilon,</span><br><span class="line">        is_training=is_training,</span><br><span class="line">        data_format=data_format)</span><br><span class="line">    logits = model.forward_pass(feature, input_data_format=<span class="string">'channels_last'</span>)</span><br><span class="line">    pred = &#123;</span><br><span class="line">        <span class="string">'classes'</span>: tf.argmax(input=logits, axis=<span class="number">1</span>),</span><br><span class="line">        <span class="string">'probabilities'</span>: tf.nn.softmax(logits)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    loss = tf.losses.sparse_softmax_cross_entropy(</span><br><span class="line">        logits=logits, labels=label)</span><br><span class="line">    loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">    model_params = tf.trainable_variables()</span><br><span class="line">    loss += weight_decay * tf.add_n([tf.nn.l2_loss(v) <span class="keyword">for</span> v <span class="keyword">in</span> model_params])</span><br><span class="line">    grad = tf.gradients(loss, model_params)</span><br><span class="line">    <span class="keyword">return</span> loss, zip(grad, model_params), pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_dir,</span></span></span><br><span class="line"><span class="function"><span class="params">            subset,</span></span></span><br><span class="line"><span class="function"><span class="params">            num_shards,</span></span></span><br><span class="line"><span class="function"><span class="params">            batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">            use_distortion_for_training=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    输入函数，可以用于train数据集合eval数据集</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_dir：tfrecords文件所在的文件夹</span></span><br><span class="line"><span class="string">        subset：判断是train还是evaluate</span></span><br><span class="line"><span class="string">        batch_size：一个batch的大小</span></span><br><span class="line"><span class="string">        use_distortion_for_training：是否对数据进行扰动</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        image_batch：一个batch的image数据</span></span><br><span class="line"><span class="string">        label_batch：一个batch的label数据</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">        use_distortion = subset == <span class="string">'train'</span> <span class="keyword">and</span> use_distortion_for_training</span><br><span class="line">        dataset = cifar10.Cifar10DataSet(data_dir, subset, use_distortion)</span><br><span class="line">        image_batch, label_batch = dataset.make_batch(batch_size)</span><br><span class="line">        <span class="keyword">if</span> num_shards &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> [image_batch], [label_batch] <span class="comment"># 必须返回list，对应_calc_fn的参数</span></span><br><span class="line">        <span class="comment"># 均分训练数据给不同的设备</span></span><br><span class="line">        image_batch = tf.unstack(image_batch, num=batch_size, axis=<span class="number">0</span>)</span><br><span class="line">        label_batch = tf.unstack(label_batch, num=batch_size, axis=<span class="number">0</span>)</span><br><span class="line">        feature_shards = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(num_shards)]</span><br><span class="line">        label_shards = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(num_shards)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size):</span><br><span class="line">            idx = i % num_shards</span><br><span class="line">            feature_shards[idx].append(image_batch[i])</span><br><span class="line">            label_shards[idx].append(label_batch[i])</span><br><span class="line">        feature_shards = [tf.parallel_stack(x) <span class="keyword">for</span> x <span class="keyword">in</span> feature_shards]</span><br><span class="line">        label_shards = [tf.parallel_stack(x) <span class="keyword">for</span> x <span class="keyword">in</span> label_shards]</span><br><span class="line">        <span class="keyword">return</span> feature_shards, label_shards</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(flags)</span>:</span></span><br><span class="line">    <span class="comment"># The env variable is on deprecation path, default is set to off.</span></span><br><span class="line">    os.environ[<span class="string">'TF_SYNC_ON_FINISH'</span>] = <span class="string">'0'</span></span><br><span class="line">    os.environ[<span class="string">'TF_ENABLE_WINOGRAD_NONFUSED'</span>] = <span class="string">'1'</span></span><br><span class="line">    <span class="comment"># 为了调用多线程运行，需要使用tf.ConfigProto，</span></span><br><span class="line">    <span class="comment"># device_count指定最多使用多少devices，比如CPU，最多仅支持1；</span></span><br><span class="line">    <span class="comment"># 如果有多个GPU，可以指定最多使用其中的多少个，键值对形式</span></span><br><span class="line">    <span class="comment"># intra_op_parallelism_threads 控制运算符op内部的并行</span></span><br><span class="line">    <span class="comment"># inter_op_parallelism_threads 控制多个运算符op之间的并行计算</span></span><br><span class="line">    run_config = tf.ConfigProto(</span><br><span class="line">        device_count=&#123;<span class="string">"CPU"</span>: <span class="number">1</span>, <span class="string">"GPU"</span>: <span class="number">0</span>&#125;,</span><br><span class="line">        allow_soft_placement=<span class="literal">True</span>, <span class="comment"># GPU显存相关，自动增加</span></span><br><span class="line">        log_device_placement=flags.log_device_placement,</span><br><span class="line">        gpu_options=tf.GPUOptions(force_gpu_compatible=<span class="literal">True</span>),</span><br><span class="line">        intra_op_parallelism_threads=flags.num_intra_threads,</span><br><span class="line">        inter_op_parallelism_threads=flags.num_inter_threads)</span><br><span class="line">    <span class="comment"># tf.ConfigProto不能直接添加到Estimator中，</span></span><br><span class="line">    <span class="comment"># 需要使用tf.estimator.RunConfig包裹一下，顺便指定模型存储路径model_dir</span></span><br><span class="line">    config = tf.estimator.RunConfig(</span><br><span class="line">        model_dir=flags.job_dir,</span><br><span class="line">        session_config=run_config)</span><br><span class="line">    <span class="comment"># tf.estimator.Estimator的params必须是dict类型</span></span><br><span class="line">    classifier = tf.estimator.Estimator(</span><br><span class="line">        model_fn=get_model_fn(</span><br><span class="line">            flags.num_gpus, </span><br><span class="line">            flags.variable_strategy, </span><br><span class="line">            config.num_worker_replicas <span class="keyword">or</span> <span class="number">1</span>),</span><br><span class="line">        config=config,</span><br><span class="line">        params=&#123;</span><br><span class="line">            <span class="string">'decay_steps'</span>: flags.decay_steps,</span><br><span class="line">            <span class="string">'decay_rate'</span>: flags.decay_rate,</span><br><span class="line">            <span class="string">'num_layers'</span>: flags.num_layers,</span><br><span class="line">            <span class="string">'weight_decay'</span>: flags.weight_decay,</span><br><span class="line">            <span class="string">'batch_norm_decay'</span>: flags.batch_norm_decay,</span><br><span class="line">            <span class="string">'batch_norm_epsilon'</span>: flags.batch_norm_epsilon,</span><br><span class="line">            <span class="string">'train_batch_size'</span>: flags.train_batch_size,</span><br><span class="line">            <span class="string">'learning_rate'</span>: flags.learning_rate,</span><br><span class="line">            <span class="string">'data_format'</span>: flags.data_format,</span><br><span class="line">            <span class="string">'sync'</span>: flags.sync,</span><br><span class="line">            <span class="string">'is_chief'</span>:config.is_chief</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="comment"># 循环多次以观察eval的变化，防止过拟合</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        classifier.train(input_fn=<span class="keyword">lambda</span>: input_fn(</span><br><span class="line">            flags.data_dir, <span class="string">'train'</span>, flags.num_gpus, flags.train_batch_size), </span><br><span class="line">            steps=flags.train_steps)</span><br><span class="line">        classifier.evaluate(input_fn=<span class="keyword">lambda</span>: input_fn(</span><br><span class="line">            flags.data_dir, <span class="string">'eval'</span>, flags.num_gpus, flags.eval_batch_size),</span><br><span class="line">            steps=flags.eval_steps)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(FLAGS.data_dir):</span><br><span class="line">        os.mkdir(FLAGS.data_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(FLAGS.job_dir):</span><br><span class="line">        os.mkdir(FLAGS.job_dir)      </span><br><span class="line">    <span class="comment"># 下面是对参数的一些约束，比如使用GPU数量与ResNet网络层数的逻辑约束等</span></span><br><span class="line">    <span class="keyword">if</span> FLAGS.num_gpus &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> tf.test.is_gpu_available(), <span class="string">'Requested GPUs but none found.'</span></span><br><span class="line">    <span class="keyword">if</span> FLAGS.num_gpus &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">        <span class="string">'Invalid GPU count: \"--num-gpus\" must be 0 or a positive integer.'</span>)</span><br><span class="line">    <span class="keyword">if</span> FLAGS.num_gpus == <span class="number">0</span> <span class="keyword">and</span> FLAGS.variable_strategy == <span class="string">'GPU'</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'num-gpus=0, CPU must be used as parameter server. Set'</span></span><br><span class="line">                     <span class="string">'--variable-strategy=CPU.'</span>)</span><br><span class="line">    <span class="keyword">if</span> (FLAGS.num_layers - <span class="number">2</span>) % <span class="number">6</span> != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid --num-layers parameter.'</span>)</span><br><span class="line">    <span class="keyword">if</span> FLAGS.num_gpus != <span class="number">0</span> <span class="keyword">and</span> FLAGS.train_batch_size % FLAGS.num_gpus != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'--train-batch-size must be multiple of --num-gpus.'</span>)</span><br><span class="line">    <span class="keyword">if</span> FLAGS.num_gpus != <span class="number">0</span> <span class="keyword">and</span> FLAGS.eval_batch_size % FLAGS.num_gpus != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'--eval-batch-size must be multiple of --num-gpus.'</span>)</span><br><span class="line">    <span class="keyword">if</span> cifar10.Cifar10DataSet.num_examples_per_epoch(<span class="string">'eval'</span>) % FLAGS.eval_batch_size != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'validation set size must be multiple of eval_batch_size'</span>)</span><br><span class="line"></span><br><span class="line">    tf.app.run(main(FLAGS))</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
      
  <div class="popular-posts-header">推荐文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/40b4de0.html" rel="bookmark">TensorFlow-CIFAR10</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/2d6320ff.html" rel="bookmark">神经网络-coding</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/c516f6f0.html" rel="bookmark">线性模型-coding</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/120687ac.html" rel="bookmark">决策树-coding</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/archives/28da5216.html" rel="bookmark">循环神经网络-coding</a></div>
    </li>
  </ul>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Tao Zhou
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://zhoutao822.coding.me/archives/467d5b64.html" title="卷积神经网络-coding">http://zhoutao822.coding.me/archives/467d5b64.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Code/" rel="tag"># Code</a>
              <a href="/tags/Estimator/" rel="tag"># Estimator</a>
              <a href="/tags/Keras/" rel="tag"># Keras</a>
              <a href="/tags/CNN/" rel="tag"># CNN</a>
              <a href="/tags/MNIST/" rel="tag"># MNIST</a>
              <a href="/tags/CIFAR-10/" rel="tag"># CIFAR-10</a>
              <a href="/tags/Kaggle-dog-cat/" rel="tag"># Kaggle dog & cat</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/archives/850721b0.html" rel="prev" title="语音识别-RBM和DBN">
      <i class="fa fa-chevron-left"></i> 语音识别-RBM和DBN
    </a></div>
      <div class="post-nav-item">
    <a href="/archives/a1207629.html" rel="next" title="深度学习-激活函数">
      深度学习-激活函数 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-数据集说明"><span class="nav-text"> 1. 数据集说明</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#11-多分类图像数据集-mnist"><span class="nav-text"> 1.1 多分类图像数据集-MNIST</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-二分类图像数据集-kaggle-dog-cat"><span class="nav-text"> 1.2 二分类图像数据集-kaggle dog &amp; cat</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-多分类数据集-cifar-10"><span class="nav-text"> 1.3 多分类数据集-CIFAR-10</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-tensorflow卷积神经网络应用"><span class="nav-text"> 2. Tensorflow卷积神经网络应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#21-eager模式实现手写数字分类"><span class="nav-text"> 2.1 Eager模式实现手写数字分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#22-keras实现手写数字分类"><span class="nav-text"> 2.2 Keras实现手写数字分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#23-基于keras使用预训练的网络实现猫狗识别"><span class="nav-text"> 2.3 基于Keras使用预训练的网络实现猫狗识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#24-使用预训练模型fine-tuning完成猫狗识别"><span class="nav-text"> 2.4 使用预训练模型fine-tuning完成猫狗识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#25-自定义estimator-cifar10识别"><span class="nav-text"> 2.5 自定义Estimator-CIFAR10识别</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tao Zhou"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Tao Zhou</p>
  <div class="site-description" itemprop="description">学习笔记</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tao Zhou</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">955k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:28</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    url = encodeURI(url);
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.getAttribute('id'));
      var title = visitors.getAttribute('data-flag-title');

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
              leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .catch(error => {
                console.error('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.getAttribute('id'));
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
            'X-LC-Key': 'xoukWFyqvFIXJ6DfxLLYtsTP',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'iyNzyQRx6yCU5YQVEXPl0hSe-gzGzoHsz',
      appKey: 'xoukWFyqvFIXJ6DfxLLYtsTP',
      placeholder: "Just go go",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: false,
      lang: 'zh-cn' || 'zh-cn',
      path: location.pathname,
      recordIP: true,
      serverURLs: ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
